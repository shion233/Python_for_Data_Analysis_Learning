{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "429a40f3",
   "metadata": {},
   "source": [
    "# 利用Python进行数据分析（第二版）——第五章 pandas入门"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d42d667",
   "metadata": {},
   "source": [
    "## pandas入门 (页码: p166)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29899bb8",
   "metadata": {},
   "source": [
    "## 1. pandas入门\n",
    "#### 页码: p166\n",
    "\n",
    "### 1.1 章节概述\n",
    "pandas是Python中用于数据分析的核心库，提供了高效的数据结构和操作工具。本节介绍了pandas的基本用法，包括导入库和设置环境，为后续学习打下基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c69450",
   "metadata": {},
   "source": [
    "### 1.2 代码与注释\n",
    "\n",
    "#### 导入基础库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "819de60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# - **注释**:  \n",
    "#   - `numpy` 是数值计算的基础库，pandas依赖其进行底层运算。  \n",
    "#   - `pandas` 是数据分析的核心库，提供了Series和DataFrame等数据结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624f5a3",
   "metadata": {},
   "source": [
    "#### 导入Series和DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48109b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "\n",
    "# - **注释**:  \n",
    "#   - `Series` 是一维带标签的数据结构，类似于带索引的数组。  \n",
    "#   - `DataFrame` 是二维表格数据结构，类似于Excel表格或数据库表。  \n",
    "#   - 通过 `from ... import` 直接引入，避免每次使用时写全名（如 `pd.Series`）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f95b8a4",
   "metadata": {},
   "source": [
    "#### 设置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a41c08c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(12345)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"figure\", figsize=(10, 6))\n",
    "PREVIOUS_MAX_ROWS = pd.options.display.max_rows\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_colwidth = 80\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "# - **关键知识点**:  \n",
    "#   - **`np.random.seed(12345)`**: 确保随机数生成一致，便于教学和调试。  \n",
    "#   - **`plt.rc`**: 配置matplotlib绘图参数，调整图形大小以便更清晰地展示数据。  \n",
    "#   - **`pd.options.display`**: 控制pandas输出格式，避免显示过多行或列，提高可读性。  \n",
    "#   - **`np.set_printoptions`**: 美化numpy数组输出，适合数据分析展示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b38020",
   "metadata": {},
   "source": [
    "### 1.3 本节重点\n",
    "- **目标**: 熟悉pandas的导入和基本配置。  \n",
    "- **工具**: `numpy`、`pandas` 和 `matplotlib` 是数据分析的三大核心库。  \n",
    "- **环境设置**: 通过调整显示选项和随机种子，确保代码输出的可读性和可重复性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce401226",
   "metadata": {},
   "source": [
    "## pandas的数据结构介绍 (页码: p166)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dcacf8",
   "metadata": {},
   "source": [
    "## 2. pandas的数据结构介绍\n",
    "#### 页码: p166\n",
    "\n",
    "### 2.1 章节概述\n",
    "本节介绍了pandas的两个核心数据结构：**Series** 和 **DataFrame**。Series 是一维带标签的数组，DataFrame 是二维表格数据结构。通过示例代码，展示了如何创建、操作和访问这些数据结构，以及处理缺失值和索引等关键功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae2af81",
   "metadata": {},
   "source": [
    "### 2.2 代码与注释\n",
    "\n",
    "#### 2.2.1 Series 的基本操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a21df7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    7\n",
       "2   -5\n",
       "3    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = pd.Series([4, 7, -5, 3])\n",
    "obj\n",
    "\n",
    "# - **注释**:\n",
    "#   - `pd.Series` 创建一个一维数组，自动分配默认整数索引（从0开始）。\n",
    "#   - `dtype: int64` 表示数据类型为64位整数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fb26ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=4, step=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.array\n",
    "obj.index\n",
    "\n",
    "# - **注释**:\n",
    "#   - `obj.array` 返回Series的底层数据（PandasArray类型）。\n",
    "#   - `obj.index` 返回Series的索引对象（默认是 `RangeIndex(0, 1, 2, 3)`）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d57db5e",
   "metadata": {},
   "source": [
    "#### 2.2.2 自定义索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc0f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 = pd.Series([4, 7, -5, 3], index=[\"d\", \"b\", \"a\", \"c\"])\n",
    "obj2\n",
    "obj2.index\n",
    "\n",
    "# - **注释**:\n",
    "#   - 通过 `index` 参数自定义索引，索引可以是字符串或其他类型。\n",
    "#   - `obj2.index` 返回自定义的索引对象（`Index` 类型）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "d    4\n",
    "b    7\n",
    "a   -5\n",
    "c    3\n",
    "dtype: int64\n",
    "\n",
    "Index(['d', 'b', 'a', 'c'], dtype='object')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e803142f",
   "metadata": {},
   "source": [
    "#### 2.2.3 访问和修改Series元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4da298",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[\"a\"]\n",
    "obj2[\"d\"] = 6\n",
    "obj2[[\"c\", \"a\", \"d\"]]\n",
    "\n",
    "# - **注释**:\n",
    "#   - 使用索引标签（如 `\"a\"`）访问单个元素。\n",
    "#   - 通过赋值（如 `obj2[\"d\"] = 6`）修改指定索引的值。\n",
    "#   - 使用列表（如 `[\"c\", \"a\", \"d\"]`）访问多个元素，返回新的Series。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "-5\n",
    "\n",
    "c    3\n",
    "a   -5\n",
    "d    6\n",
    "dtype: int64\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a867c692",
   "metadata": {},
   "source": [
    "#### 2.2.4 条件筛选和数学运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c66e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[obj2 > 0]\n",
    "obj2 * 2\n",
    "import numpy as np\n",
    "np.exp(obj2)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `obj2[obj2 > 0]` 使用布尔条件筛选正数值。\n",
    "#   - `obj2 * 2` 对整个Series进行标量运算，索引保持不变。\n",
    "#   - `np.exp(obj2)` 应用NumPy的数学函数，计算每个元素的指数。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "d    6\n",
    "b    7\n",
    "c    3\n",
    "dtype: int64\n",
    "\n",
    "d    12\n",
    "b    14\n",
    "a   -10\n",
    "c     6\n",
    "dtype: int64\n",
    "\n",
    "d     403.428793\n",
    "b    1096.633158\n",
    "a       0.006738\n",
    "c      20.085537\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be299540",
   "metadata": {},
   "source": [
    "#### 2.2.5 成员检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"b\" in obj2\n",
    "\"e\" in obj2\n",
    "\n",
    "# - **注释**:\n",
    "#   - 使用 `in` 操作符检查索引是否存在，返回布尔值（`True` 或 `False`）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08777e8",
   "metadata": {},
   "source": [
    "#### 2.2.6 从字典创建Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e5991",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = {\"Ohio\": 35000, \"Texas\": 71000, \"Oregon\": 16000, \"Utah\": 5000}\n",
    "obj3 = pd.Series(sdata)\n",
    "obj3\n",
    "\n",
    "# - **注释**:\n",
    "#   - 字典的键成为Series的索引，值成为对应的数据。\n",
    "#   - Series会自动按字典键的顺序排列。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Ohio      35000\n",
    "Texas     71000\n",
    "Oregon    16000\n",
    "Utah       5000\n",
    "dtype: int64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca3e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj3.to_dict()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `to_dict()` 将Series转换回字典，方便与其他Python代码集成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9065b4",
   "metadata": {},
   "source": [
    "#### 2.2.7 自定义索引顺序和缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"California\", \"Ohio\", \"Oregon\", \"Texas\"]\n",
    "obj4 = pd.Series(sdata, index=states)\n",
    "obj4\n",
    "\n",
    "# - **注释**:\n",
    "#   - 使用指定的 `index` 参数重新排序，若索引在原数据中不存在（如 `\"California\"`），则值为 `NaN`（缺失值）。\n",
    "#   - 数据类型从 `int64` 变为 `float64`，因为 `NaN` 是浮点类型。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "California        NaN\n",
    "Ohio          35000.0\n",
    "Oregon        16000.0\n",
    "Texas         71000.0\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc53caf",
   "metadata": {},
   "source": [
    "#### 2.2.8 检测缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d7b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(obj4)\n",
    "pd.notna(obj4)\n",
    "obj4.isna()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `pd.isna()` 和 `obj4.isna()` 检查每个元素是否为 `NaN`，返回布尔Series。\n",
    "#   - `pd.notna()` 检查非缺失值，返回相反的布尔Series。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99271707",
   "metadata": {},
   "source": [
    "#### 2.2.9 Series 之间的运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e437889",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj3\n",
    "obj4\n",
    "obj3 + obj4\n",
    "\n",
    "# - **注释**:\n",
    "#   - Series相加时，索引会自动对齐。\n",
    "#   - 如果某个索引只存在于一个Series中，结果为 `NaN`。\n",
    "#   - 运算会保留所有索引的并集。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "California         NaN\n",
    "Ohio           70000.0\n",
    "Oregon         32000.0\n",
    "Texas         142000.0\n",
    "Utah               NaN\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2769bf3",
   "metadata": {},
   "source": [
    "#### 2.2.10 设置名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj4.name = \"population\"\n",
    "obj4.index.name = \"state\"\n",
    "obj4\n",
    "\n",
    "# - **注释**:\n",
    "#   - `obj4.name` 为Series设置名称，用于标识数据含义。\n",
    "#   - `obj4.index.name` 为索引设置名称，增强数据的语义化。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "state\n",
    "California        NaN\n",
    "Ohio          35000.0\n",
    "Oregon        16000.0\n",
    "Texas         71000.0\n",
    "Name: population, dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1a1577",
   "metadata": {},
   "source": [
    "#### 2.2.11 修改索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043edbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj\n",
    "obj.index = [\"Bob\", \"Steve\", \"Jeff\", \"Ryan\"]\n",
    "obj\n",
    "\n",
    "# - **注释**:\n",
    "#   - 直接赋值修改Series的索引，长度必须与数据匹配。\n",
    "#   - 索引修改不影响数据内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9497535",
   "metadata": {},
   "source": [
    "### 2.3 本节重点\n",
    "- **Series**:\n",
    "  - 一维带标签数组，支持自定义索引。\n",
    "  - 支持基于索引的访问、修改、筛选和数学运算。\n",
    "  - 可从字典创建，自动对齐索引。\n",
    "  - 支持缺失值处理（`NaN`）和索引名称设置。\n",
    "- **关键操作**:\n",
    "  - 创建：`pd.Series(data, index=...)`\n",
    "  - 访问：`obj[\"label\"]` 或 `obj[[\"label1\", \"label2\"]]`\n",
    "  - 运算：支持NumPy函数和索引对齐的加减。\n",
    "  - 缺失值：`pd.isna()`、`pd.notna()`。\n",
    "- **注意事项**:\n",
    "  - 索引对齐是pandas的核心特性，确保数据操作的准确性。\n",
    "  - 缺失值会导致数据类型变为浮点型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d65293",
   "metadata": {},
   "source": [
    "## DataFrame (页码: p173)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a5b24",
   "metadata": {},
   "source": [
    "## 3. DataFrame\n",
    "#### 页码: p173\n",
    "\n",
    "### 3.1 章节概述\n",
    "**DataFrame** 是pandas中的二维表格数据结构，类似于Excel表格或SQL表，包含行索引和列索引。本节通过示例展示了如何创建DataFrame、访问和修改数据、处理缺失值以及添加/删除列等操作，强调了DataFrame的灵活性和强大功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b43e0",
   "metadata": {},
   "source": [
    "### 3.2 代码与注释\n",
    "\n",
    "#### 3.2.1 创建DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42bb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\"],\n",
    "        \"year\": [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "        \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "frame = pd.DataFrame(data)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `pd.DataFrame` 从字典创建表格，字典的键成为列名，值成为列数据。\n",
    "#   - 自动生成默认整数行索引（0到5）。\n",
    "#   - 列按字典键的顺序排列。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "    state  year  pop\n",
    "0    Ohio  2000  1.5\n",
    "1    Ohio  2001  1.7\n",
    "2    Ohio  2002  3.6\n",
    "3  Nevada  2001  2.4\n",
    "4  Nevada  2002  2.9\n",
    "5  Nevada  2003  3.2\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad7c2f9",
   "metadata": {},
   "source": [
    "#### 3.2.2 查看DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a158356",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame\n",
    "frame.head()\n",
    "frame.tail()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `frame.head()` 显示前5行（默认），用于快速预览数据。\n",
    "#   - `frame.tail()` 显示最后5行（默认），用于检查数据末尾。\n",
    "#   - 这些方法不修改原数据，仅返回视图。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "    state  year  pop\n",
    "0    Ohio  2000  1.5\n",
    "1    Ohio  2001  1.7\n",
    "2    Ohio  2002  3.6\n",
    "3  Nevada  2001  2.4\n",
    "4  Nevada  2002  2.9\n",
    "5  Nevada  2003  3.2\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3950c1c9",
   "metadata": {},
   "source": [
    "#### 3.2.3 自定义列顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57712ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\"])\n",
    "\n",
    "# - **注释**:\n",
    "#   - 通过 `columns` 参数指定列顺序，重新排列DataFrame。\n",
    "#   - 如果指定了不存在的列（如后续示例中的 `debt`），该列将填充 `NaN`。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   year   state  pop\n",
    "0  2000    Ohio  1.5\n",
    "1  2001    Ohio  1.7\n",
    "2  2002    Ohio  3.6\n",
    "3  2001  Nevada  2.4\n",
    "4  2002  Nevada  2.9\n",
    "5  2003  Nevada  3.2\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f01107",
   "metadata": {},
   "source": [
    "#### 3.2.4 添加空列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a16ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2 = pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\", \"debt\"])\n",
    "frame2\n",
    "frame2.columns\n",
    "\n",
    "# - **注释**:\n",
    "#   - 新增的 `debt` 列未在原始 `data` 中，因此值全为 `NaN`。\n",
    "#   - `frame2.columns` 返回列索引对象（`Index` 类型），列出所有列名。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   year   state  pop debt\n",
    "0  2000    Ohio  1.5  NaN\n",
    "1  2001    Ohio  1.7  NaN\n",
    "2  2002    Ohio  3.6  NaN\n",
    "3  2001  Nevada  2.4  NaN\n",
    "4  2002  Nevada  2.9  NaN\n",
    "5  2003  Nevada  3.2  NaN\n",
    "\n",
    "Index(['year', 'state', 'pop', 'debt'], dtype='object')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd26b3",
   "metadata": {},
   "source": [
    "#### 3.2.5 访问列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e45482",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2[\"state\"]\n",
    "frame2.year\n",
    "\n",
    "# - **注释**:\n",
    "#   - 使用 `frame2[\"state\"]` 或 `frame2.state` 访问单列，返回Series对象。\n",
    "#   - 点号访问（如 `frame2.year`）更简洁，但仅适用于合法的Python变量名（无空格或特殊字符）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0      Ohio\n",
    "1      Ohio\n",
    "2      Ohio\n",
    "3    Nevada\n",
    "4    Nevada\n",
    "5    Nevada\n",
    "Name: state, dtype: object\n",
    "\n",
    "0    2000\n",
    "1    2001\n",
    "2    2002\n",
    "3    2001\n",
    "4    2002\n",
    "5    2003\n",
    "Name: year, dtype: int64\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20335be4",
   "metadata": {},
   "source": [
    "#### 3.2.6 访问行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba382995",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.loc[1]\n",
    "# frame2.iloc[2]  # 注释中提到但未执行\n",
    "\n",
    "# - **注释**:\n",
    "#   - `frame2.loc[1]` 按标签访问行，返回Series（列名作为索引）。\n",
    "#   - `frame2.iloc[2]`（未执行）按整数位置访问行，适合没有显式行标签的情况。\n",
    "#   - `loc` 使用标签，`iloc` 使用位置，区分明确以避免混淆。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "year     2001\n",
    "state    Ohio\n",
    "pop       1.7\n",
    "debt      NaN\n",
    "Name: 1, dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d430efbf",
   "metadata": {},
   "source": [
    "#### 3.2.7 修改列数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2[\"debt\"] = 16.5\n",
    "frame2\n",
    "frame2[\"debt\"] = np.arange(6.)\n",
    "frame2\n",
    "\n",
    "# - **注释**:\n",
    "#   - `frame2[\"debt\"] = 16.5` 将整个 `debt` 列设为标量值 16.5。\n",
    "#   - `frame2[\"debt\"] = np.arange(6.)` 用数组赋值，长度必须与行数匹配。\n",
    "#   - 数组赋值会覆盖之前的值，类型变为浮点数（`float64`）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   year   state  pop  debt\n",
    "0  2000    Ohio  1.5   0.0\n",
    "1  2001    Ohio  1.7   1.0\n",
    "2  2002    Ohio  3.6   2.0\n",
    "3  2001  Nevada  2.4   3.0\n",
    "4  2002  Nevada  2.9   4.0\n",
    "5  2003  Nevada  3.2   5.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d79aadd",
   "metadata": {},
   "source": [
    "#### 3.2.8 使用Series赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee9355",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.Series([-1.2, -1.5, -1.7], index=[\"two\", \"four\", \"five\"])\n",
    "frame2[\"debt\"] = val\n",
    "frame2\n",
    "\n",
    "# - **注释**:\n",
    "#   - 使用Series赋值时，索引会与DataFrame的行索引对齐。\n",
    "#   - 由于 `val` 的索引（`\"two\", \"four\", \"five\"`）与 `frame2` 的行索引（0到5）不匹配，`debt` 列全变为 `NaN`。\n",
    "#   - 索引对齐是pandas的核心特性，未匹配的索引会导致缺失值。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   year   state  pop  debt\n",
    "0  2000    Ohio  1.5   NaN\n",
    "1  2001    Ohio  1.7   NaN\n",
    "2  2002    Ohio  3.6   NaN\n",
    "3  2001  Nevada  2.4   NaN\n",
    "4  2002  Nevada  2.9   NaN\n",
    "5  2003  Nevada  3.2   NaN\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a46e755",
   "metadata": {},
   "source": [
    "#### 3.2.9 添加布尔列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea0bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2[\"eastern\"] = frame2[\"state\"] == \"Ohio\"\n",
    "frame2\n",
    "\n",
    "# - **注释**:\n",
    "#   - `frame2[\"state\"] == \"Ohio\"` 生成布尔Series，判断每行是否为 `\"Ohio\"`。\n",
    "#   - 赋值给新列 `eastern`，表示各州是否位于东部（此处以Ohio为例）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   year   state  pop  debt  eastern\n",
    "0  2000    Ohio  1.5   NaN     True\n",
    "1  2001    Ohio  1.7   NaN     True\n",
    "2  2002    Ohio  3.6   NaN     True\n",
    "3  2001  Nevada  2.4   NaN    False\n",
    "4  2002  Nevada  2.9   NaN    False\n",
    "5  2003  Nevada  3.2   NaN    False\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e52549",
   "metadata": {},
   "source": [
    "#### 3.2.10 删除列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df376871",
   "metadata": {},
   "outputs": [],
   "source": [
    "del frame2[\"eastern\"]\n",
    "frame2.columns\n",
    "\n",
    "# - **注释**:\n",
    "#   - `del` 语句删除指定列，修改原DataFrame。\n",
    "#   - `frame2.columns` 确认列已更新，`eastern` 列被移除。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Index(['year', 'state', 'pop', 'debt'], dtype='object')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de681f00",
   "metadata": {},
   "source": [
    "#### 3.2.11 从嵌套字典创建DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e61fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = {\"Ohio\": {2000: 1.5, 2001: 1.7, 2002: 3.6},\n",
    "               \"Nevada\": {2001: 2.4, 2002: 2.9}}\n",
    "frame3 = pd.DataFrame(populations)\n",
    "frame3\n",
    "\n",
    "# - **注释**:\n",
    "#   - 嵌套字典的外层键（`\"Ohio\", \"Nevada\"`）成为列名，内层键（年份）成为行索引。\n",
    "#   - 缺失的数据（如Nevada的2000年）填充为 `NaN`。\n",
    "#   - 行索引自动按并集排序。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "      Ohio  Nevada\n",
    "2000   1.5     NaN\n",
    "2001   1.7     2.4\n",
    "2002   3.6     2.9\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2886fe0c",
   "metadata": {},
   "source": [
    "#### 3.2.12 转置DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b0e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.T\n",
    "\n",
    "# - **注释**:\n",
    "#   - `frame3.T` 转置DataFrame，交换行和列。\n",
    "#   - 转置不修改原数据，仅返回新视图。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "        2000  2001  2002\n",
    "Ohio    1.5   1.7   3.6\n",
    "Nevada  NaN   2.4   2.9\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282841b1",
   "metadata": {},
   "source": [
    "#### 3.2.13 指定索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce45431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(populations, index=[2001, 2002, 2003])\n",
    "\n",
    "# - **注释**:\n",
    "#   - 使用 `index` 参数指定行索引，未匹配的索引（如2003）填充 `NaN`。\n",
    "#   - 索引顺序由参数决定。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "      Ohio  Nevada\n",
    "2001   1.7     2.4\n",
    "2002   3.6     2.9\n",
    "2003   NaN     NaN\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2052a7ba",
   "metadata": {},
   "source": [
    "#### 3.2.14 从Series创建DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82be948",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = {\"Ohio\": frame3[\"Ohio\"][:-1],\n",
    "         \"Nevada\": frame3[\"Nevada\"][:2]}\n",
    "pd.DataFrame(pdata)\n",
    "\n",
    "# - **注释**:\n",
    "#   - 从Series切片创建新DataFrame，`[:-1]` 取Ohio的前两行，`[:2]` 取Nevada的前两行。\n",
    "#   - 行索引自动对齐，未匹配的索引（如Nevada的2000）为 `NaN`。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "      Ohio  Nevada\n",
    "2000   1.5     NaN\n",
    "2001   1.7     2.4\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352e287",
   "metadata": {},
   "source": [
    "#### 3.2.15 设置名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7201f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.index.name = \"year\"\n",
    "frame3.columns.name = \"state\"\n",
    "frame3\n",
    "\n",
    "# - **注释**:\n",
    "#   - `index.name` 为行索引设置名称（`\"year\"`）。\n",
    "#   - `columns.name` 为列索引设置名称（`\"state\"`），增强表格语义。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "state  Ohio  Nevada\n",
    "year\n",
    "2000    1.5     NaN\n",
    "2001    1.7     2.4\n",
    "2002    3.6     2.9\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31714cb3",
   "metadata": {},
   "source": [
    "#### 3.2.16 转换为NumPy数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5632e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.to_numpy()\n",
    "frame2.to_numpy()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `to_numpy()` 将DataFrame转换为NumPy数组，仅保留数据部分，丢弃索引和列名。\n",
    "#   - 适合与NumPy或其他需要数组的库集成。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "array([[1.5, nan],\n",
    "       [1.7, 2.4],\n",
    "       [3.6, 2.9]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dd54f4",
   "metadata": {},
   "source": [
    "### 3.3 本节重点\n",
    "- **DataFrame**:\n",
    "  - 二维表格数据结构，包含行索引和列索引。\n",
    "  - 支持从字典、嵌套字典或Series创建，自动处理索引对齐和缺失值。\n",
    "  - 提供灵活的访问方式（`loc`, `iloc`, 列访问）和修改功能。\n",
    "- **关键操作**:\n",
    "  - 创建：`pd.DataFrame(data, columns=..., index=...)`\n",
    "  - 访问列：`frame[\"col\"]` 或 `frame.col`\n",
    "  - 访问行：`frame.loc[label]` 或 `frame.iloc[pos]`\n",
    "  - 修改：标量赋值、数组赋值或Series赋值（注意索引对齐）。\n",
    "  - 删除列：`del frame[\"col\"]`\n",
    "  - 转置：`frame.T`\n",
    "  - 转换为数组：`frame.to_numpy()`\n",
    "- **注意事项**:\n",
    "  - 索引对齐是DataFrame操作的核心，需注意缺失值的影响。\n",
    "  - 列名和索引名可设置以提高数据可读性。\n",
    "  - `loc` 和 `iloc` 的使用场景需明确区分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d04dc9",
   "metadata": {},
   "source": [
    "## 索引对象 (页码: p181)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3571d9",
   "metadata": {},
   "source": [
    "## 4. 索引对象\n",
    "#### 页码: p181\n",
    "\n",
    "### 4.1 章节概述\n",
    "pandas的索引对象（`Index`）用于存储Series和DataFrame的行索引或列索引，具有不可变性和类似集合的操作特性。本节介绍了索引的创建、属性、方法以及在数据操作中的作用，强调索引的唯一性和对齐功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3a83cc",
   "metadata": {},
   "source": [
    "### 4.2 代码与注释\n",
    "\n",
    "#### 4.2.1 创建索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7050fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(range(3), index=[\"a\", \"b\", \"c\"])\n",
    "index = obj.index\n",
    "index\n",
    "index[1:]\n",
    "\n",
    "# - **注释**:\n",
    "#   - `obj.index` 返回Series的索引对象（`Index` 类型），存储标签 `\"a\", \"b\", \"c\"`。\n",
    "#   - `index[1:]` 支持切片操作，返回子索引（`Index` 类型）。\n",
    "#   - 索引对象是不可变的，不能通过赋值修改（如 `index[1] = \"d\"` 会报错）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Index(['a', 'b', 'c'], dtype='object')\n",
    "Index(['b', 'c'], dtype='object')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beee988",
   "metadata": {},
   "source": [
    "#### 4.2.2 索引不可变性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = pd.Index([1, 2, 3])  # 注释中提到但未执行\n",
    "# labels[1] = 7  # 会报错，索引不可修改\n",
    "\n",
    "# - **注释**:\n",
    "#   - 索引对象的不可变性保证了数据结构的稳定性，防止意外修改。\n",
    "#   - 尝试修改索引元素会抛出 `TypeError`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1cf68",
   "metadata": {},
   "source": [
    "#### 4.2.3 创建显式索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cab54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.Index(np.arange(3))\n",
    "labels\n",
    "obj2 = pd.Series([1.5, -2.5, 0], index=labels)\n",
    "obj2\n",
    "obj2.index is labels\n",
    "\n",
    "# - **注释**:\n",
    "#   - `pd.Index(np.arange(3))` 显式创建整数索引（`Int64Index`）。\n",
    "#   - 将索引赋给Series，`obj2.index` 与 `labels` 是同一对象（`is` 返回 `True`）。\n",
    "#   - 索引可以重复使用，节省内存。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Int64Index([0, 1, 2], dtype='int64')\n",
    "0    1.5\n",
    "1   -2.5\n",
    "2    0.0\n",
    "dtype: float64\n",
    "True\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d24f92",
   "metadata": {},
   "source": [
    "#### 4.2.4 DataFrame中的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3\n",
    "frame3.columns\n",
    "\"Ohio\" in frame3.columns\n",
    "2003 in frame3.index\n",
    "\n",
    "# - **注释**:\n",
    "#   - `frame3.columns` 返回列索引（`Index` 类型），包含 `\"Ohio\", \"Nevada\"`。\n",
    "#   - `frame3.index` 返回行索引（年份，如2000, 2001, 2002）。\n",
    "#   - 使用 `in` 操作符检查标签是否存在于索引中，返回布尔值。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "state  Ohio  Nevada\n",
    "year\n",
    "2000    1.5     NaN\n",
    "2001    1.7     2.4\n",
    "2002    3.6     2.9\n",
    "Index(['Ohio', 'Nevada'], dtype='object', name='state')\n",
    "True\n",
    "False\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848968ba",
   "metadata": {},
   "source": [
    "#### 4.2.5 索引的集合操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_labels = pd.Index([\"foo\", \"foo\", \"bar\", \"bar\"])\n",
    "dup_labels\n",
    "\n",
    "# - **注释**:\n",
    "#   - 索引允许重复标签（如 `\"foo\"` 出现两次），但在某些操作中可能需要注意。\n",
    "#   - 索引对象支持类似集合的方法，如 `union`、`intersection` 等（未在代码中展示）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Index(['foo', 'foo', 'bar', 'bar'], dtype='object')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec8634",
   "metadata": {},
   "source": [
    "### 4.3 本节重点\n",
    "- **索引对象**:\n",
    "  - `Index` 是pandas中存储行/列标签的对象，不可变，支持切片和集合操作。\n",
    "  - 常见的索引类型包括 `Index`（通用）、`Int64Index`（整数）、`MultiIndex`（多级索引，书中后续章节介绍）。\n",
    "- **关键操作**:\n",
    "  - 创建：`pd.Index(data)` 或通过Series/DataFrame的 `index` 属性获取。\n",
    "  - 访问：支持切片（如 `index[1:]`）和成员检查（如 `\"label\" in index`）。\n",
    "  - 特性：不可变、允许重复标签、支持集合操作。\n",
    "- **注意事项**:\n",
    "  - 索引的不可变性保证了数据一致性。\n",
    "  - 重复索引可能影响某些操作，需谨慎处理。\n",
    "  - 索引在数据对齐中起关键作用（如Series和DataFrame的运算）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73208079",
   "metadata": {},
   "source": [
    "## 基本功能 (页码: p182)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bec9be9",
   "metadata": {},
   "source": [
    "## 5. 基本功能\n",
    "#### 页码: p189\n",
    "\n",
    "### 2.1 章节概述\n",
    "本节介绍了pandas中Series和DataFrame的基本操作，包括重新索引、删除数据、索引与选择、算术运算、函数应用和排序等。这些功能是数据清洗和分析的基础，强调了索引对齐和缺失值处理的重要性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b8a5f5",
   "metadata": {},
   "source": [
    "### 5.2 代码与注释\n",
    "\n",
    "#### 2.2.1 重新索引（Series）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49be840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "obj = pd.Series([4.5, 7.2, -5.3, 3.6], index=[\"d\", \"b\", \"a\", \"c\"])\n",
    "obj\n",
    "\n",
    "# - **注释**:\n",
    "#   - 创建一个Series，索引为字符串标签（`\"d\", \"b\", \"a\", \"c\"`）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "d    4.5\n",
    "b    7.2\n",
    "a   -5.3\n",
    "c    3.6\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb1a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 = obj.reindex([\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "obj2\n",
    "\n",
    "# - **注释**:\n",
    "#   - `reindex` 重新排列索引，新索引（如 `\"e\"`）不存在时填充 `NaN`。\n",
    "#   - 原有索引顺序被调整为指定的顺序（`\"a\", \"b\", \"c\", \"d\", \"e\"`）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "a   -5.3\n",
    "b    7.2\n",
    "c    3.6\n",
    "d    4.5\n",
    "e    NaN\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3168aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj3 = pd.Series([\"blue\", \"purple\", \"yellow\"], index=[0, 2, 4])\n",
    "obj3\n",
    "obj3.reindex(np.arange(6), method=\"ffill\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `reindex(np.arange(6))` 扩展索引到0到5，缺失值默认填充 `NaN`。\n",
    "#   - `method=\"ffill\"` 使用前向填充（forward fill），将前一个值填充到新索引。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0      blue\n",
    "2    purple\n",
    "4    yellow\n",
    "dtype: object\n",
    "\n",
    "0      blue\n",
    "1      blue\n",
    "2    purple\n",
    "3    purple\n",
    "4    yellow\n",
    "5    yellow\n",
    "dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13997797",
   "metadata": {},
   "source": [
    "#### 5.2.2 重新索引（DataFrame）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.arange(9).reshape((3, 3)),\n",
    "                     index=[\"a\", \"c\", \"d\"],\n",
    "                     columns=[\"Ohio\", \"Texas\", \"California\"])\n",
    "frame\n",
    "frame2 = frame.reindex(index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "frame2\n",
    "\n",
    "# - **注释**:\n",
    "#   - `frame` 是一个3x3的DataFrame，数据为0到8，索引为 `\"a\", \"c\", \"d\"`，列名为 `\"Ohio\", \"Texas\", \"California\"`。\n",
    "#   - `reindex(index=...)` 调整行索引，新索引 `\"b\"` 填充 `NaN`。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   Ohio  Texas  California\n",
    "a     0      1           2\n",
    "c     3      4           5\n",
    "d     6      7           8\n",
    "\n",
    "   Ohio  Texas  California\n",
    "a   0.0    1.0         2.0\n",
    "b   NaN    NaN         NaN\n",
    "c   3.0    4.0         5.0\n",
    "d   6.0    7.0         8.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dec2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"Texas\", \"Utah\", \"California\"]\n",
    "frame.reindex(columns=states)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `reindex(columns=...)` 调整列索引，新列 `\"Utah\"` 填充 `NaN`，未指定的列（如 `\"Ohio\"`）被移除。\n",
    "#   - 列顺序按 `states` 列表排列。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   Texas  Utah  California\n",
    "a      1   NaN         2\n",
    "c      4   NaN         5\n",
    "d      7   NaN         8\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de16e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.reindex(states, axis=\"columns\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - 使用 `axis=\"columns\"` 显式指定调整列索引，等效于 `reindex(columns=states)`。\n",
    "#   - `axis` 参数使代码更清晰，推荐在复杂操作中使用。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   Texas  Utah  California\n",
    "a      1   NaN         2\n",
    "c      4   NaN         5\n",
    "d      7   NaN         8\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5584600a",
   "metadata": {},
   "source": [
    "#### 5.2.3 删除数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(5.), index=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "obj\n",
    "new_obj = obj.drop(\"c\")\n",
    "new_obj\n",
    "obj.drop([\"d\", \"c\"])\n",
    "\n",
    "# - **注释**:\n",
    "#   - `drop(\"c\")` 删除指定索引的行，返回新Series，原对象不变。\n",
    "#   - `drop([\"d\", \"c\"])` 删除多个索引，返回新Series。\n",
    "#   - `drop` 默认不修改原对象，需赋值或使用 `inplace=True`.\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "a    0.0\n",
    "b    1.0\n",
    "c    2.0\n",
    "d    3.0\n",
    "e    4.0\n",
    "dtype: float64\n",
    "\n",
    "a    0.0\n",
    "b    1.0\n",
    "d    3.0\n",
    "e    4.0\n",
    "dtype: float64\n",
    "\n",
    "a    0.0\n",
    "b    1.0\n",
    "e    4.0\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
    "                    index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"],\n",
    "                    columns=[\"one\", \"two\", \"three\", \"four\"])\n",
    "data\n",
    "data.drop(index=[\"Colorado\", \"Ohio\"])\n",
    "data.drop(columns=[\"two\"])\n",
    "data.drop(\"two\", axis=1)\n",
    "data.drop([\"two\", \"four\"], axis=\"columns\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `drop(index=...)` 删除指定行，`drop(columns=...)` 删除指定列。\n",
    "#   - `drop(..., axis=1)` 等效于 `drop(columns=...)`，显式指定轴更清晰。\n",
    "#   - 删除操作返回新DataFrame，原对象不变。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "        one  two  three  four\n",
    "Ohio      0    1      2     3\n",
    "Colorado  4    5      6     7\n",
    "Utah      8    9     10    11\n",
    "New York 12   13     14    15\n",
    "\n",
    "        one  two  three  four\n",
    "Utah      8    9     10    11\n",
    "New York 12   13     14    15\n",
    "\n",
    "        one  three  four\n",
    "Ohio      0      2     3\n",
    "Colorado  4      6     7\n",
    "Utah      8     10    11\n",
    "New York 12     14    15\n",
    "\n",
    "        one  three  four\n",
    "Ohio      0      2     3\n",
    "Colorado  4      6     7\n",
    "Utah      8     10    11\n",
    "New York 12     14    15\n",
    "\n",
    "        one  three\n",
    "Ohio      0      2\n",
    "Colorado  4      6\n",
    "Utah      8     10\n",
    "New York 12     14\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8068006b",
   "metadata": {},
   "source": [
    "#### 5.2.4 索引与选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(4.), index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "obj\n",
    "obj[\"b\"]\n",
    "obj[1]\n",
    "obj[2:4]\n",
    "obj[[\"b\", \"a\", \"d\"]]\n",
    "obj[[1, 3]]\n",
    "obj[obj < 2]\n",
    "\n",
    "# - **注释**:\n",
    "#   - `obj[\"b\"]` 或 `obj[1]` 按标签或位置访问单个元素。\n",
    "#   - `obj[2:4]` 按位置切片，返回子Series。\n",
    "#   - `obj[[\"b\", \"a\", \"d\"]]` 按标签列表选择多个元素。\n",
    "#   - `obj[[1, 3]]` 按位置列表选择多个元素。\n",
    "#   - `obj[obj < 2]` 使用布尔条件筛选，返回满足条件的子Series。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "a    0.0\n",
    "b    1.0\n",
    "c    2.0\n",
    "d    3.0\n",
    "dtype: float64\n",
    "\n",
    "1.0\n",
    "\n",
    "1.0\n",
    "\n",
    "c    2.0\n",
    "d    3.0\n",
    "dtype: float64\n",
    "\n",
    "b    1.0\n",
    "a    0.0\n",
    "d    3.0\n",
    "dtype: float64\n",
    "\n",
    "a    0.0\n",
    "d    3.0\n",
    "dtype: float64\n",
    "\n",
    "a    0.0\n",
    "b    1.0\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.loc[[\"b\", \"a\", \"d\"]]\n",
    "obj.iloc[[1, 0, 3]]\n",
    "obj.loc[\"b\":\"c\"]\n",
    "\n",
    "# - **注释**:\n",
    "#   - `loc` 按标签选择，`iloc` 按位置选择。\n",
    "#   - `loc[\"b\":\"c\"]` 包含结束标签（闭区间），与Python切片不同。\n",
    "#   - 推荐使用 `loc` 和 `iloc` 以明确意图，避免混淆。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "b    1.0\n",
    "a    0.0\n",
    "d    3.0\n",
    "dtype: float64\n",
    "\n",
    "b    1.0\n",
    "a    0.0\n",
    "d    3.0\n",
    "dtype: float64\n",
    "\n",
    "b    1.0\n",
    "c    2.0\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.loc[\"a\":\"c\"] = 5\n",
    "obj\n",
    "\n",
    "# - **注释**:\n",
    "#   - `loc` 支持赋值，修改指定范围的值。\n",
    "#   - 赋值会直接修改原Series。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "a    5.0\n",
    "b    5.0\n",
    "c    5.0\n",
    "d    3.0\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff1b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
    "                    index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"],\n",
    "                    columns=[\"one\", \"two\", \"three\", \"four\"])\n",
    "data\n",
    "data[\"two\"]\n",
    "data[[\"three\", \"one\"]]\n",
    "data[:2]\n",
    "data[data[\"three\"] > 5]\n",
    "data < 5\n",
    "\n",
    "# - **注释**:\n",
    "#   - `data[\"two\"]` 选择单列，返回Series。\n",
    "#   - `data[[\"three\", \"one\"]]` 选择多列，返回DataFrame。\n",
    "#   - `data[:2]` 按位置切片，选择前两行。\n",
    "#   - `data[data[\"three\"] > 5]` 按条件筛选行。\n",
    "#   - `data < 5` 返回布尔DataFrame，标记每个元素是否满足条件.\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "        one  two  three  four\n",
    "Ohio      0    1      2     3\n",
    "Colorado  4    5      6     7\n",
    "Utah      8    9     10    11\n",
    "New York 12   13     14    15\n",
    "\n",
    "Ohio         1\n",
    "Colorado     5\n",
    "Utah         9\n",
    "New York    13\n",
    "Name: two, dtype: int64\n",
    "\n",
    "        three  one\n",
    "Ohio        2    0\n",
    "Colorado    6    4\n",
    "Utah       10    8\n",
    "New York   14   12\n",
    "\n",
    "        one  two  three  four\n",
    "Ohio      0    1      2     3\n",
    "Colorado  4    5      6     7\n",
    "\n",
    "        one  two  three  four\n",
    "Colorado  4    5      6     7\n",
    "Utah      8    9     10    11\n",
    "New York 12   13     14    15\n",
    "\n",
    "        one   two  three  four\n",
    "Ohio      True  True   True  True\n",
    "Colorado  True False  False False\n",
    "Utah     False False  False False\n",
    "New York False False  False False\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2697bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\"Colorado\"]\n",
    "data.loc[[\"Colorado\", \"New York\"]]\n",
    "data.loc[\"Colorado\", [\"two\", \"three\"]]\n",
    "data.iloc[2]\n",
    "data.iloc[[2, 1]]\n",
    "data.iloc[2, [3, 0, 1]]\n",
    "data.iloc[[1, 2], [3, 0, 1]]\n",
    "\n",
    "# - **注释**:\n",
    "#   - `loc` 按标签选择行或行列子集，`iloc` 按位置选择。\n",
    "#   - `data.loc[\"Colorado\", [\"two\", \"three\"]]` 选择特定行和列的子集。\n",
    "#   - 推荐使用 `loc` 和 `iloc` 以提高代码可读性和明确性。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "one      4\n",
    "two      5\n",
    "three    6\n",
    "four     7\n",
    "Name: Colorado, dtype: int64\n",
    "\n",
    "        one  two  three  four\n",
    "Colorado  4    5      6     7\n",
    "New York 12   13     14    15\n",
    "\n",
    "two      5\n",
    "three    6\n",
    "Name: Colorado, dtype: int64\n",
    "\n",
    "one       8\n",
    "two       9\n",
    "three    10\n",
    "four     11\n",
    "Name: Utah, dtype: int64\n",
    "\n",
    "        one  two  three  four\n",
    "Utah      8    9     10    11\n",
    "Colorado  4    5      6     7\n",
    "\n",
    "four    11\n",
    "one      8\n",
    "two      9\n",
    "Name: Utah, dtype: int64\n",
    "\n",
    "        four  one  two\n",
    "Colorado     7    4    5\n",
    "Utah        11    8    9\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:\"Utah\", \"two\"]\n",
    "data.iloc[:, :3][data.three > 5]\n",
    "\n",
    "# - **注释**:\n",
    "#   - `data.loc[:\"Utah\", \"two\"]` 选择从开头到 `\"Utah\"` 的 `\"two\"` 列。\n",
    "#   - `data.iloc[:, :3][data.three > 5]` 先选择前三列，再筛选 `\"three\"` 列大于5的行。\n",
    "#   - 链式索引可能导致性能问题，建议合并操作。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Ohio        1\n",
    "Colorado    5\n",
    "Utah        9\n",
    "Name: two, dtype: int64\n",
    "\n",
    "        one  two  three\n",
    "Colorado  4    5      6\n",
    "Utah      8    9     10\n",
    "New York 12   13     14\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6476e8e",
   "metadata": {},
   "source": [
    "#### 5.2.5 算术运算与数据对齐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=[\"a\", \"c\", \"d\", \"e\"])\n",
    "s2 = pd.Series([-2.1, 3.6, -1.5, 4.0, 3.1], index=[\"a\", \"c\", \"e\", \"f\", \"g\"])\n",
    "s1\n",
    "s2\n",
    "s1 + s2\n",
    "\n",
    "# - **注释**:\n",
    "#   - Series相加时，索引自动对齐，仅对共同索引计算。\n",
    "#   - 不匹配的索引（如 `\"d\", \"f\", \"g\"`）结果为 `NaN`。\n",
    "#   - 索引对齐是pandas的核心特性。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "a    7.3\n",
    "c   -2.5\n",
    "d    3.4\n",
    "e    1.5\n",
    "dtype: float64\n",
    "\n",
    "a   -2.1\n",
    "c    3.6\n",
    "e   -1.5\n",
    "f    4.0\n",
    "g    3.1\n",
    "dtype: float64\n",
    "\n",
    "a    5.2\n",
    "c    1.1\n",
    "d    NaN\n",
    "e    0.0\n",
    "f    NaN\n",
    "g    NaN\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caaed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(9.).reshape((3, 3)),\n",
    "                   columns=list(\"bcd\"),\n",
    "                   index=[\"Ohio\", \"Texas\", \"Colorado\"])\n",
    "df2 = pd.DataFrame(np.arange(12.).reshape((4, 3)),\n",
    "                   columns=list(\"bde\"),\n",
    "                   index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "df1\n",
    "df2\n",
    "df1 + df2\n",
    "\n",
    "# - **注释**:\n",
    "#   - DataFrame相加时，行索引和列索引同时对齐。\n",
    "#   - 不匹配的索引或列（如 `\"c\", \"e\", \"Colorado\", \"Utah\", \"Oregon\"`）结果为 `NaN`。\n",
    "#   - 结果包含所有行和列的并集。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "        b    c    d\n",
    "Ohio    0.0  1.0  2.0\n",
    "Texas   3.0  4.0  5.0\n",
    "Colorado 6.0 7.0 8.0\n",
    "\n",
    "        b     d     e\n",
    "Utah    0.0   1.0   2.0\n",
    "Ohio    3.0   4.0   5.0\n",
    "Texas   6.0   7.0   8.0\n",
    "Oregon  9.0  10.0  11.0\n",
    "\n",
    "           b   c     d   e\n",
    "Colorado NaN NaN   NaN NaN\n",
    "Ohio     3.0 NaN   6.0 NaN\n",
    "Oregon  NaN NaN   NaN NaN\n",
    "Texas    9.0 NaN  12.0 NaN\n",
    "Utah    NaN NaN   NaN NaN\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(12.).reshape((3, 4)),\n",
    "                   columns=list(\"abcd\"))\n",
    "df2 = pd.DataFrame(np.arange(20.).reshape((4, 5)),\n",
    "                   columns=list(\"abcde\"))\n",
    "df1\n",
    "df2\n",
    "df2.loc[1, \"b\"] = np.nan\n",
    "df1 + df2\n",
    "\n",
    "# - **注释**:\n",
    "#   - 修改 `df2.loc[1, \"b\"] = np.nan` 引入缺失值。\n",
    "#   - 相加时，缺失值传播到结果，任何运算涉及 `NaN` 结果为 `NaN`。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "     a    b     c     d\n",
    "0  0.0  1.0   2.0   3.0\n",
    "1  4.0  5.0   6.0   7.0\n",
    "2  8.0  9.0  10.0  11.0\n",
    "\n",
    "      a     b     c     d     e\n",
    "0   0.0   1.0   2.0   3.0   4.0\n",
    "1   5.0   NaN   7.0   8.0   9.0\n",
    "2  10.0  11.0  12.0  13.0  14.0\n",
    "3  15.0  16.0  17.0  18.0  19.0\n",
    "\n",
    "      a     b     c     d   e\n",
    "0   0.0   2.0   4.0   6.0 NaN\n",
    "1   9.0   NaN  13.0  15.0 NaN\n",
    "2  18.0  20.0  22.0  24.0 NaN\n",
    "3   NaN   NaN   NaN   NaN NaN\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34119ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.add(df2, fill_value=0)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `add(fill_value=0)` 在运算前用0填充缺失值（仅对索引不匹配的部分）。\n",
    "#   - 已有 `NaN`（如 `df2.loc[1, \"b\"]`）不会被填充，需单独处理。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "      a     b     c     d     e\n",
    "0   0.0   2.0   4.0   6.0   4.0\n",
    "1   9.0   5.0  13.0  15.0   9.0\n",
    "2  18.0  20.0  22.0  24.0  14.0\n",
    "3  15.0  16.0  17.0  18.0  19.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e846438a",
   "metadata": {},
   "source": [
    "#### 5.2.6 DataFrame与Series的运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.arange(12.).reshape((4, 3)),\n",
    "                     columns=list(\"bde\"),\n",
    "                     index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "series = frame.iloc[0]\n",
    "frame\n",
    "series\n",
    "frame - series\n",
    "\n",
    "# - **注释**:\n",
    "#   - `frame - series` 按列广播，Series的每个值减去对应列的值。\n",
    "#   - 索引对齐确保运算正确，广播机制类似NumPy。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "        b     d     e\n",
    "Utah    0.0   1.0   2.0\n",
    "Ohio    3.0   4.0   5.0\n",
    "Texas   6.0   7.0   8.0\n",
    "Oregon  9.0  10.0  11.0\n",
    "\n",
    "b    0.0\n",
    "d    1.0\n",
    "e    2.0\n",
    "Name: Utah, dtype: float64\n",
    "\n",
    "        b    d    e\n",
    "Utah    0.0  0.0  0.0\n",
    "Ohio    3.0  3.0  3.0\n",
    "Texas   6.0  6.0  6.0\n",
    "Oregon  9.0  9.0  9.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6683cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "series2 = pd.Series(np.arange(3), index=[\"b\", \"e\", \"f\"])\n",
    "series2\n",
    "frame + series2\n",
    "\n",
    "# - **注释**:\n",
    "#   - 不匹配的索引（如 `\"f\"`）或列（如 `\"d\"`）导致 `NaN`。\n",
    "#   - 默认按列广播，需确保索引匹配。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "b    0\n",
    "e    1\n",
    "f    2\n",
    "dtype: int64\n",
    "\n",
    "        b   d     e   f\n",
    "Utah    0.0 NaN   3.0 NaN\n",
    "Ohio    3.0 NaN   6.0 NaN\n",
    "Texas   6.0 NaN   9.0 NaN\n",
    "Oregon  9.0 NaN  12.0 NaN\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f269658",
   "metadata": {},
   "outputs": [],
   "source": [
    "series3 = frame[\"d\"]\n",
    "frame\n",
    "series3\n",
    "frame.sub(series3, axis=\"index\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `sub(..., axis=\"index\")` 按行广播，Series的每个值减去对应行的值。\n",
    "#   - `axis=\"index\"` 改变广播方向，需明确指定。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "        b     d     e\n",
    "Utah    0.0   1.0   2.0\n",
    "Ohio    3.0   4.0   5.0\n",
    "Texas   6.0   7.0   8.0\n",
    "Oregon  9.0  10.0  11.0\n",
    "\n",
    "Utah       1.0\n",
    "Ohio       4.0\n",
    "Texas      7.0\n",
    "Oregon    10.0\n",
    "Name: d, dtype: float64\n",
    "\n",
    "        b    d    e\n",
    "Utah   -1.0  0.0  1.0\n",
    "Ohio   -1.0  0.0  1.0\n",
    "Texas  -1.0  0.0  1.0\n",
    "Oregon -1.0  0.0  1.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966c1335",
   "metadata": {},
   "source": [
    "#### 5.2.7 函数应用与映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.random.standard_normal((4, 3)),\n",
    "                     columns=list(\"bde\"),\n",
    "                     index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "frame\n",
    "np.abs(frame)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `np.random.standard_normal` 生成标准正态分布随机数。\n",
    "#   - `np.abs(frame)` 对每个元素应用绝对值函数，返回新DataFrame。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "             b         d         e\n",
    "Utah   -0.204708  0.478943 -0.519439\n",
    "Ohio   -0.555730  1.965781  1.393406\n",
    "Texas   0.092908  0.281746  0.769023\n",
    "Oregon  1.246435  1.007189 -1.296221\n",
    "\n",
    "             b         d         e\n",
    "Utah    0.204708  0.478943  0.519439\n",
    "Ohio    0.555730  1.965781  1.393406\n",
    "Texas   0.092908  0.281746  0.769023\n",
    "Oregon  1.246435  1.007189  1.296221\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "frame.apply(f1)\n",
    "frame.apply(f1, axis=\"columns\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `apply(f1)` 对每列应用函数 `f1`，返回最大值与最小值的差（Series）。\n",
    "#   - `apply(f1, axis=\"columns\")` 对每行应用函数，返回每行的极差。\n",
    "#   - `apply` 适合逐行或逐列应用自定义函数。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "b    1.802165\n",
    "d    1.684835\n",
    "e    2.689644\n",
    "dtype: float64\n",
    "\n",
    "Utah      0.998651\n",
    "Ohio      2.521511\n",
    "Texas     0.676115\n",
    "Oregon    2.542656\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e8fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    return pd.Series([x.min(), x.max()], index=[\"min\", \"max\"])\n",
    "frame.apply(f2)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `f2` 返回包含最小值和最大值的Series。\n",
    "#   - `apply(f2)` 对每列应用 `f2`，结果组成DataFrame，行索引为 `\"min\", \"max\"`。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "        b         d         e\n",
    "min -0.555730  0.281746 -1.296221\n",
    "max  1.246435  1.965781  1.393406\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504170f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_format(x):\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "frame.applymap(my_format)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `applymap` 对每个元素应用函数，此处格式化为两位小数。\n",
    "#   - 适合逐元素操作，返回新DataFrame。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "        b      d      e\n",
    "Utah   -0.20   0.48  -0.52\n",
    "Ohio   -0.56   1.97   1.39\n",
    "Texas   0.09   0.28   0.77\n",
    "Oregon  1.25   1.01  -1.30\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[\"e\"].map(my_format)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `map` 对Series的每个元素应用函数，返回新Series。\n",
    "#   - 仅适用于Series，功能类似 `applymap` 但更高效。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Utah      -0.52\n",
    "Ohio       1.39\n",
    "Texas      0.77\n",
    "Oregon    -1.30\n",
    "Name: e, dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8274ed",
   "metadata": {},
   "source": [
    "#### 5.2.8 排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa43ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(4), index=[\"d\", \"a\", \"b\", \"c\"])\n",
    "obj.sort_index()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `sort_index()` 按索引排序（升序），返回新Series。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "a    1\n",
    "b    2\n",
    "c    3\n",
    "d    0\n",
    "dtype: int64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75712a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.arange(8).reshape((2, 4)),\n",
    "                     index=[\"three\", \"one\"],\n",
    "                     columns=[\"d\", \"a\", \"b\", \"c\"])\n",
    "frame\n",
    "frame.sort_index()\n",
    "frame.sort_index(axis=1)\n",
    "frame.sort_index(axis=1, ascending=False)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `sort_index()` 按行索引排序（默认 `axis=0`）。\n",
    "#   - `sort_index(axis=1)` 按列索引排序。\n",
    "#   - `ascending=False` 按降序排序。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "       d  a  b  c\n",
    "three  0  1  2  3\n",
    "one    4  5  6  7\n",
    "\n",
    "       d  a  b  c\n",
    "one    4  5  6  7\n",
    "three  0  1  2  3\n",
    "\n",
    "       a  b  c  d\n",
    "three  1  2  3  0\n",
    "one    5  6  7  4\n",
    "\n",
    "       d  c  b  a\n",
    "three  0  3  2  1\n",
    "one    4  7  6  5\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3086ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([4, 7, -3, 2])\n",
    "obj.sort_values()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `sort_values()` 按值排序（升序），返回新Series。\n",
    "#   - 索引随之调整。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "2   -3\n",
    "3    2\n",
    "0    4\n",
    "1    7\n",
    "dtype: int64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([4, np.nan, 7, np.nan, -3, 2])\n",
    "obj.sort_values()\n",
    "obj.sort_values(na_position=\"first\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `sort_values()` 默认将 `NaN` 放在末尾。\n",
    "#   - `na_position=\"first\"` 将 `NaN` 放在开头。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "4   -3.0\n",
    "5    2.0\n",
    "0    4.0\n",
    "2    7.0\n",
    "1    NaN\n",
    "3    NaN\n",
    "dtype: float64\n",
    "\n",
    "1    NaN\n",
    "3    NaN\n",
    "4   -3.0\n",
    "5    2.0\n",
    "0    4.0\n",
    "2    7.0\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({\"b\": [4, 7, -3, 2], \"a\": [0, 1, 0, 1]})\n",
    "frame\n",
    "frame.sort_values(\"b\")\n",
    "frame.sort_values([\"a\", \"b\"])\n",
    "\n",
    "# - **注释**:\n",
    "#   - `sort_values(\"b\")` 按 `\"b\"` 列值排序。\n",
    "#   - `sort_values([\"a\", \"b\"])` 先按 `\"a\"` 排序，再按 `\"b\"` 排序。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   b  a\n",
    "0  4  0\n",
    "1  7  1\n",
    "2 -3  0\n",
    "3  2  1\n",
    "\n",
    "   b  a\n",
    "2 -3  0\n",
    "3  2  1\n",
    "0  4  0\n",
    "1  7  1\n",
    "\n",
    "   b  a\n",
    "2 -3  0\n",
    "0  4  0\n",
    "3  2  1\n",
    "1  7  1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e7df41",
   "metadata": {},
   "source": [
    "#### 5.2.9 排名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([7, -5, 7, 4, 2, 0, 4])\n",
    "obj.rank()\n",
    "obj.rank(method=\"first\")\n",
    "obj.rank(ascending=False, method=\"max\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `rank()` 计算每个值的排名（升序），相同值取平均排名（如7的排名为6.5）。\n",
    "#   - `method=\"first\"` 按出现顺序分配排名，打破平局。\n",
    "#   - `ascending=False, method=\"max\"` 按降序排名，相同值取最大排名。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0    6.5\n",
    "1    1.0\n",
    "2    6.5\n",
    "3    4.5\n",
    "4    3.0\n",
    "5    2.0\n",
    "6    4.5\n",
    "dtype: float64\n",
    "\n",
    "0    6.0\n",
    "1    1.0\n",
    "2    7.0\n",
    "3    4.0\n",
    "4    3.0\n",
    "5    2.0\n",
    "6    5.0\n",
    "dtype: float64\n",
    "\n",
    "0    2.0\n",
    "1    7.0\n",
    "2    2.0\n",
    "3    4.0\n",
    "4    5.0\n",
    "5    6.0\n",
    "6    4.0\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b4e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({\"b\": [4.3, 7, -3, 2], \"a\": [0, 1, 0, 1],\n",
    "                      \"c\": [-2, 5, 8, -2.5]})\n",
    "frame\n",
    "frame.rank(axis=\"columns\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `rank(axis=\"columns\")` 对每行内的值排名，生成排名DataFrame。\n",
    "#   - 每行独立排名，值越大排名越高（升序）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "     b  a    c\n",
    "0  4.3  0 -2.0\n",
    "1  7.0  1  5.0\n",
    "2 -3.0  0  8.0\n",
    "3  2.0  1 -2.5\n",
    "\n",
    "     b    a    c\n",
    "0  3.0  2.0  1.0\n",
    "1  3.0  1.0  2.0\n",
    "2  1.0  2.0  3.0\n",
    "3  3.0  2.0  1.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d087ab",
   "metadata": {},
   "source": [
    "### 5.3 本节重点\n",
    "- **重新索引**:\n",
    "  - `reindex()` 调整Series或DataFrame的行/列索引，缺失值填充 `NaN` 或使用 `ffill` 等方法。\n",
    "  - 支持 `axis` 参数，灵活调整行或列。\n",
    "- **删除数据**:\n",
    "  - `drop()` 删除指定行或列，默认返回新对象，需 `inplace=True` 修改原对象。\n",
    "  - 支持 `index` 和 `columns` 参数，清晰指定删除目标。\n",
    "- **索引与选择**:\n",
    "  - `loc`（标签索引）和 `iloc`（位置索引）是首选方法，明确且高效。\n",
    "  - 支持切片、布尔索引和多标签选择，注意 `loc` 切片的闭区间特性。\n",
    "- **算术运算**:\n",
    "  - 索引对齐是pandas核心，自动处理不匹配索引（填充 `NaN`）。\n",
    "  - `add()`, `sub()` 等方法支持 `fill_value` 控制缺失值。\n",
    "  - DataFrame与Series运算支持广播，需指定 `axis`（`index` 或 `columns`）。\n",
    "- **函数应用**:\n",
    "  - `apply()` 逐行/列应用函数，`applymap()` 逐元素操作，`map()` 适用于Series。\n",
    "  - 适合自定义计算或格式化输出。\n",
    "- **排序与排名**:\n",
    "  - `sort_index()` 按索引排序，`sort_values()` 按值排序，支持 `ascending` 和 `na_position`。\n",
    "  - `rank()` 计算排名，`method` 参数控制平局处理（如 `\"first\"`, `\"max\"`）。\n",
    "- **注意事项**:\n",
    "  - 操作默认返回新对象，需注意是否需要赋值或使用 `inplace=True`。\n",
    "  - 链式索引（如 `df.iloc[:, :3][condition]`）可能导致性能问题，尽量合并操作。\n",
    "  - 缺失值（`NaN`）在运算中传播，需提前处理或使用 `fill_value`。\n",
    "  - 索引对齐和广播需仔细检查，确保结果符合预期。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c035747",
   "metadata": {},
   "source": [
    "## 汇总和计算描述统计 (页码: p194)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393bc4b",
   "metadata": {},
   "source": [
    "## 6. 汇总和计算描述统计\n",
    "#### 页码: p194\n",
    "\n",
    "### 6.1 章节概述\n",
    "本节介绍了pandas中用于汇总和计算描述统计的方法，如求和、均值、方差等，适用于Series和DataFrame。这些方法支持处理缺失值、指定轴向和跳过缺失值的选项，是数据分析中的核心工具。本节还展示了相关性、唯一值统计和值计数等功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f01bb",
   "metadata": {},
   "source": [
    "### 6.2 代码与注释\n",
    "\n",
    "#### 6.2.1 基本统计方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5],\n",
    "                   [np.nan, np.nan], [0.75, -1.3]],\n",
    "                  index=[\"a\", \"b\", \"c\", \"d\"],\n",
    "                  columns=[\"one\", \"two\"])\n",
    "df\n",
    "\n",
    "# - **注释**:\n",
    "#   - 创建一个包含缺失值（`NaN`）的DataFrame，行索引为 `\"a\", \"b\", \"c\", \"d\"`，列名为 `\"one\", \"two\"`。\n",
    "#   - 缺失值在统计计算中会影响结果，需注意处理方式。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "    one  two\n",
    "a  1.40  NaN\n",
    "b  7.10 -4.5\n",
    "c   NaN  NaN\n",
    "d  0.75 -1.3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `sum()` 默认沿 `axis=0`（列方向）计算每列的和。\n",
    "#   - 自动跳过 `NaN`，仅对非缺失值求和。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "one    9.25\n",
    "two   -5.80\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda7f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=\"columns\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `axis=\"columns\"` 沿行方向计算每行的和。\n",
    "#   - 行中若全为 `NaN`（如 `c`），结果为 0；若部分为 `NaN`，仅对非缺失值求和。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "a    1.40\n",
    "b    2.60\n",
    "c    0.00\n",
    "d   -0.55\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=\"columns\", skipna=False)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `skipna=False` 要求计算时不跳过 `NaN`，只要行中有 `NaN`，结果为 `NaN`。\n",
    "#   - 适合需要严格数据完整性的场景。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "a     NaN\n",
    "b    2.60\n",
    "c     NaN\n",
    "d   -0.55\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b4861",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=\"columns\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `mean()` 计算每行的均值，默认跳过 `NaN`。\n",
    "#   - 行 `c` 全为 `NaN`，结果为 `NaN`。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "a    1.400\n",
    "b    1.300\n",
    "c      NaN\n",
    "d   -0.275\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a247c2",
   "metadata": {},
   "source": [
    "#### 6.2.2 描述统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c454b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.idxmax()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `idxmax()` 返回每列最大值的行索引。\n",
    "#   - 对于 `NaN`，自动跳过，仅考虑非缺失值。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "one    b\n",
    "two    d\n",
    "dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b08bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cumsum()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `cumsum()` 计算每列的累计和，沿 `axis=0` 逐行累加。\n",
    "#   - `NaN` 传播到后续计算，需注意。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "    one  two\n",
    "a  1.40  NaN\n",
    "b  8.50 -4.5\n",
    "c   NaN  NaN\n",
    "d  9.25 -5.8\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261551d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `describe()` 生成描述统计，包括计数、均值、标准差、四分位数等。\n",
    "#   - 仅对数值列有效，自动跳过 `NaN`。\n",
    "#   - `count` 表示非缺失值的数量。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "            one       two\n",
    "count  3.000000  2.000000\n",
    "mean   3.083333 -2.900000\n",
    "std    3.493685  2.262742\n",
    "min    0.750000 -4.500000\n",
    "25%    1.075000 -3.700000\n",
    "50%    1.400000 -2.900000\n",
    "75%    4.250000 -2.100000\n",
    "max    7.100000 -1.300000\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e3c306",
   "metadata": {},
   "source": [
    "#### 6.2.3 非数值数据的统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d154f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([\"a\", \"a\", \"b\", \"c\"] * 4)\n",
    "obj.describe()\n",
    "\n",
    "# - **注释**:\n",
    "#   - 对于非数值Series，`describe()` 返回计数、唯一值数、最常见值（`top`）及其频率（`freq`）。\n",
    "#   - 适合分析分类数据。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "count     16\n",
    "unique     3\n",
    "top        a\n",
    "freq       8\n",
    "dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0cd3b0",
   "metadata": {},
   "source": [
    "#### 6.2.4 相关性和协方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a969d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas_datareader.data as web\n",
    "# all_data = {ticker: web.get_data_yahoo(ticker)\n",
    "#             for ticker in [\"AAPL\", \"IBM\", \" transverse\", \"GOOG\"]}\n",
    "# price = pd.DataFrame({ticker: data[\"Adj Close\"]\n",
    "#                      for ticker, data in all_data.items()})\n",
    "# volume = pd.DataFrame({ticker: data[\"Volume\"]\n",
    "#                       for ticker, data in all_data.items()})\n",
    "\n",
    "# - **注释**:\n",
    "#   - 示例代码从Yahoo Finance获取股票数据（`AAPL`, `IBM`, `MSFT`, `GOOG`），创建价格和交易量DataFrame。\n",
    "#   - 由于数据源可能不稳定，实际运行需确保网络连接和API可用性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d91e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns = price.pct_change()\n",
    "# returns.tail()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `pct_change()` 计算价格的百分比变化（日收益率）。\n",
    "#   - `tail()` 显示最后几行，用于检查数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0069b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns[\"MSFT\"].corr(returns[\"IBM\"])\n",
    "# returns[\"MSFT\"].cov(returns[\"IBM\"])\n",
    "\n",
    "# - **注释**:\n",
    "#   - `corr()` 计算两列之间的相关系数（范围-1到1）。\n",
    "#   - `cov()` 计算两列之间的协方差。\n",
    "#   - 适用于分析变量间的线性关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba232782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns.corr()\n",
    "# returns.cov()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `corr()` 返回所有列对的相关系数矩阵。\n",
    "#   - `cov()` 返回所有列对的协方差矩阵。\n",
    "#   - 对角线为1（`corr`）或自身方差（`cov`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns.corrwith(returns[\"IBM\"])\n",
    "\n",
    "# - **注释**:\n",
    "#   - `corrwith()` 计算某列（`IBM`）与DataFrame中所有列的相关系数。\n",
    "#   - 返回Series，索引为列名，值为相关系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b61443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns.corrwith(volume)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `corrwith()` 计算价格收益率与交易量之间的列对列相关系数。\n",
    "#   - 需确保两DataFrame的索引和列对齐。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c1f49",
   "metadata": {},
   "source": [
    "#### 6.2.5 唯一值、值计数和成员检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e7aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([\"c\", \"a\", \"d\", \"a\", \"a\", \"b\", \"b\", \"c\", \"c\"])\n",
    "uniques = obj.unique()\n",
    "uniques\n",
    "\n",
    "# - **注释**:\n",
    "#   - `unique()` 返回Series中的唯一值数组，按出现顺序排列。\n",
    "#   - 适用于分类数据分析。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "array(['c', 'a', 'd', 'b'], dtype=object)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7603b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.value_counts()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `value_counts()` 统计每个值的出现频率，返回Series（值作为索引，频率作为值）。\n",
    "#   - 默认按频率降序排列。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "c    3\n",
    "a    3\n",
    "b    2\n",
    "d    1\n",
    "dtype: int64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c369204",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(obj.to_numpy(), sort=False)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `pd.value_counts()` 直接对数组计数，`sort=False` 按值顺序返回。\n",
    "#   - 与 `obj.value_counts()` 类似，但更灵活。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "c    3\n",
    "a    3\n",
    "d    1\n",
    "b    2\n",
    "dtype: int64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = obj.isin([\"b\", \"c\"])\n",
    "mask\n",
    "obj[mask]\n",
    "\n",
    "# - **注释**:\n",
    "#   - `isin()` 检查Series的每个元素是否在指定列表（`[\"b\", \"c\"]`）中，返回布尔Series。\n",
    "#   - 使用布尔索引（如 `obj[mask]`）筛选匹配的值。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0     True\n",
    "1    False\n",
    "2    False\n",
    "3    False\n",
    "4    False\n",
    "5     True\n",
    "6     True\n",
    "7     True\n",
    "8     True\n",
    "dtype: bool\n",
    "\n",
    "0    c\n",
    "5    b\n",
    "6    b\n",
    "7    c\n",
    "8    c\n",
    "dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ccd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_match = pd.Series([\"c\", \"a\", \"b\", \"b\", \"c\", \"a\"])\n",
    "unique_vals = pd.Series([\"c\", \"b\", \"a\"])\n",
    "indices = pd.Index(unique_vals).get_indexer(to_match)\n",
    "indices\n",
    "\n",
    "# - **注释**:\n",
    "#   - `get_indexer()` 将 `to_match` 中的值映射到 `unique_vals` 的索引位置。\n",
    "#   - 返回整数数组，表示每个值在 `unique_vals` 中的位置。\n",
    "#   - 适用于编码或快速查找。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "array([0, 2, 1, 1, 0, 2])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21992c75",
   "metadata": {},
   "source": [
    "#### 6.2.6 DataFrame的值计数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558de27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Qu1\": [1, 3, 4, 3, 4],\n",
    "                     \"Qu2\": [2, 3, 1, 2, 3],\n",
    "                     \"Qu3\": [1, 5, 2, 4, 4]})\n",
    "data\n",
    "\n",
    "# - **注释**:\n",
    "#   - 创建一个DataFrame，模拟问卷数据（`Qu1`, `Qu2`, `Qu3`）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   Qu1  Qu2  Qu3\n",
    "0    1    2    1\n",
    "1    3    3    5\n",
    "2    4    1    2\n",
    "3    3    2    4\n",
    "4    4    3    4\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dad7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Qu1\"].value_counts().sort_index()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `value_counts()` 统计 `Qu1` 列中每个值的频率。\n",
    "#   - `sort_index()` 按值升序排列结果。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "1    1\n",
    "3    2\n",
    "4    2\n",
    "Name: Qu1, dtype: int64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data.apply(pd.value_counts).fillna(0)\n",
    "result\n",
    "\n",
    "# - **注释**:\n",
    "#   - `apply(pd.value_counts)` 对每列应用值计数，生成每个值在各列中的频率。\n",
    "#   - `fillna(0)` 将缺失值（未出现的计数）填充为0。\n",
    "#   - 结果DataFrame的行索引为唯一值，列为原列名，值表示频率。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   Qu1  Qu2  Qu3\n",
    "1  1.0  1.0  1.0\n",
    "2  0.0  2.0  1.0\n",
    "3  2.0  2.0  0.0\n",
    "4  2.0  0.0  2.0\n",
    "5  0.0  0.0  1.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48847c8b",
   "metadata": {},
   "source": [
    "### 6.3 本节重点\n",
    "- **描述统计**:\n",
    "  - `sum()`, `mean()`, `idxmax()`, `cumsum()`, `describe()` 等方法计算汇总统计。\n",
    "  - 默认跳过 `NaN`，可通过 `skipna=False` 更改行为。\n",
    "  - 支持 `axis` 参数，灵活选择行或列方向。\n",
    "- **相关性和协方差**:\n",
    "  - `corr()`, `cov()`, `corrwith()` 分析变量间的线性关系。\n",
    "  - 需确保数据对齐，适合时间序列或数值数据分析。\n",
    "- **唯一值与计数**:\n",
    "  - `unique()` 返回唯一值数组。\n",
    "  - `value_counts()` 统计频率，适合分类数据。\n",
    "  - `isin()` 检查成员关系，支持布尔索引。\n",
    "  - `get_indexer()` 快速映射值到索引位置。\n",
    "- **DataFrame计数**:\n",
    "  - `apply(pd.value_counts)` 统计每列的值分布，`fillna(0)` 处理缺失计数。\n",
    "- **注意事项**:\n",
    "  - 缺失值（`NaN`）对统计结果有重要影响，需明确处理方式。\n",
    "  - 索引对齐在相关性计算中至关重要。\n",
    "  - 非数值数据的统计（如 `describe()`）结果不同，需区分场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5e221",
   "metadata": {},
   "source": [
    "## 处理缺失数据 (页码: p201)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d5d03",
   "metadata": {},
   "source": [
    "## 7. 处理缺失数据\n",
    "#### 页码: p201\n",
    "\n",
    "### 7.1 章节概述\n",
    "本节介绍了pandas处理缺失数据（`NaN` 或 `None`）的方法，包括检测、过滤、填充和插值等。缺失数据是数据分析中的常见问题，pandas提供了灵活的工具来处理这些情况，以确保分析的准确性和完整性。本节强调了缺失值的检测和填充策略，以及在不同场景下的适用方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aa4db3",
   "metadata": {},
   "source": [
    "### 7.2 代码与注释\n",
    "\n",
    "#### 7.2.1 检测缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca002631",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([1, np.nan, 3.5, np.nan, 7])\n",
    "data.isnull()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `isnull()` 检查Series中的每个元素是否为缺失值（`NaN` 或 `None`），返回布尔Series。\n",
    "#   - `True` 表示该位置为缺失值。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0    False\n",
    "1     True\n",
    "2    False\n",
    "3     True\n",
    "4    False\n",
    "dtype: bool\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb24a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.notnull()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `notnull()` 与 `isnull()` 相反，返回 `True` 表示非缺失值。\n",
    "#   - 常用于筛选非缺失数据。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0     True\n",
    "1    False\n",
    "2     True\n",
    "3    False\n",
    "4     True\n",
    "dtype: bool\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb9ea1",
   "metadata": {},
   "source": [
    "#### 7.2.2 过滤缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.notnull()]\n",
    "\n",
    "# - **注释**:\n",
    "#   - 使用布尔索引（如 `data.notnull()`）过滤掉缺失值，仅保留非缺失值的元素。\n",
    "#   - 返回新的Series，原对象不变。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0    1.0\n",
    "2    3.5\n",
    "4    7.0\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c419b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([[1., 6.5, 3.], [1., np.nan, np.nan],\n",
    "                     [np.nan, np.nan, np.nan], [np.nan, 6.5, 3.]])\n",
    "data\n",
    "data.dropna()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `dropna()` 默认删除包含任何缺失值的行（`axis=0`）。\n",
    "#   - 结果只保留完整行（如第0行）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "     0    1    2\n",
    "0  1.0  6.5  3.0\n",
    "1  1.0  NaN  NaN\n",
    "2  NaN  NaN  NaN\n",
    "3  NaN  6.5  3.0\n",
    "\n",
    "     0    1    2\n",
    "0  1.0  6.5  3.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8739dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(how=\"all\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `how=\"all\"` 仅删除全为缺失值的行（如第2行）。\n",
    "#   - 保留至少有一个非缺失值的行。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "     0    1    2\n",
    "0  1.0  6.5  3.0\n",
    "1  1.0  NaN  NaN\n",
    "3  NaN  6.5  3.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d6d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[4] = np.nan\n",
    "data\n",
    "data.dropna(axis=\"columns\", how=\"all\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - 添加全为 `NaN` 的列（`4`）。\n",
    "#   - `dropna(axis=\"columns\", how=\"all\")` 删除全为缺失值的列（`4`）。\n",
    "#   - `axis=\"columns\"` 指定操作方向为列。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "     0    1    2   4\n",
    "0  1.0  6.5  3.0 NaN\n",
    "1  1.0  NaN  NaN NaN\n",
    "2  NaN  NaN  NaN NaN\n",
    "3  NaN  6.5  3.0 NaN\n",
    "\n",
    "     0    1    2\n",
    "0  1.0  6.5  3.0\n",
    "1  1.0  NaN  NaN\n",
    "2  NaN  NaN  NaN\n",
    "3  NaN  6.5  3.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f754fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.standard_normal((7, 3)))\n",
    "df.iloc[:4, 1] = np.nan\n",
    "df.iloc[:2, 2] = np.nan\n",
    "df\n",
    "df.dropna()\n",
    "df.dropna(thresh=2)\n",
    "\n",
    "# - **注释**:\n",
    "#   - 构造包含缺失值的DataFrame，列1的前4行和列2的前2行为 `NaN`。\n",
    "#   - `dropna()` 删除包含任何缺失值的行，仅保留完整行。\n",
    "#   - `thresh=2` 保留至少有2个非缺失值的行，允许部分缺失。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "           0         1         2\n",
    "0 -0.204708       NaN       NaN\n",
    "1 -0.555730       NaN       NaN\n",
    "2  0.092908       NaN  0.769023\n",
    "3  1.246435       NaN -1.296221\n",
    "4  0.274992  0.228913  1.352917\n",
    "5  0.886429 -2.001637 -0.371843\n",
    "6  1.669025 -0.438570 -0.539741\n",
    "\n",
    "           0         1         2\n",
    "4  0.274992  0.228913  1.352917\n",
    "5  0.886429 -2.001637 -0.371843\n",
    "6  1.669025 -0.438570 -0.539741\n",
    "\n",
    "           0         1         2\n",
    "2  0.092908       NaN  0.769023\n",
    "3  1.246435       NaN -1.296221\n",
    "4  0.274992  0.228913  1.352917\n",
    "5  0.886429 -2.001637 -0.371843\n",
    "6  1.669025 -0.438570 -0.539741\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072de035",
   "metadata": {},
   "source": [
    "#### 7.2.3 填充缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `fillna(0)` 将所有 `NaN` 替换为0。\n",
    "#   - 返回新DataFrame，原对象不变。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "           0         1         2\n",
    "0 -0.204708  0.000000  0.000000\n",
    "1 -0.555730  0.000000  0.000000\n",
    "2  0.092908  0.000000  0.769023\n",
    "3  1.246435  0.000000 -1.296221\n",
    "4  0.274992  0.228913  1.352917\n",
    "5  0.886429 -2.001637 -0.371843\n",
    "6  1.669025 -0.438570 -0.539741\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({1: 0.5, 2: 0})\n",
    "\n",
    "# - **注释**:\n",
    "#   - `fillna({1: 0.5, 2: 0})` 为不同列指定不同的填充值，列1填0.5，列2填0。\n",
    "#   - 未指定的列（如列0）的 `NaN` 保持不变。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "           0         1         2\n",
    "0 -0.204708  0.500000  0.000000\n",
    "1 -0.555730  0.500000  0.000000\n",
    "2  0.092908  0.500000  0.769023\n",
    "3  1.246435  0.500000 -1.296221\n",
    "4  0.274992  0.228913  1.352917\n",
    "5  0.886429 -2.001637 -0.371843\n",
    "6  1.669025 -0.438570 -0.539741\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1cd740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.standard_normal((7, 3)))\n",
    "df.iloc[:4, 1] = np.nan\n",
    "df.iloc[:2, 2] = np.nan\n",
    "df\n",
    "df.fillna(method=\"ffill\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `method=\"ffill\"`（前向填充）用前一个非缺失值填充 `NaN`。\n",
    "#   - 如果 `NaN` 前无值（如列1的前4行），则保持 `NaN`。\n",
    "#   - 注：书中提到 `method` 参数在较新版本中需替换为 `ffill()` 或 `bfill()`，但此处仍使用旧语法。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "           0         1         2\n",
    "0 -0.204708       NaN       NaN\n",
    "1 -0.555730       NaN       NaN\n",
    "2  0.092908       NaN  0.769023\n",
    "3  1.246435       NaN -1.296221\n",
    "4  0.274992  0.228913  1.352917\n",
    "5  0.886429 -2.001637 -0.371843\n",
    "6  1.669025 -0.438570 -0.539741\n",
    "\n",
    "           0         1         2\n",
    "0 -0.204708       NaN       NaN\n",
    "1 -0.555730       NaN       NaN\n",
    "2  0.092908       NaN  0.769023\n",
    "3  1.246435       NaN -1.296221\n",
    "4  0.274992  0.228913  1.352917\n",
    "5  0.886429 -2.001637 -0.371843\n",
    "6  1.669025 -0.438570 -0.539741\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e03296",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([1., np.nan, 3.5, np.nan, 7])\n",
    "data.fillna(data.mean())\n",
    "\n",
    "# - **注释**:\n",
    "#   - `fillna(data.mean())` 用Series的均值（非缺失值的平均值，约为3.833333）填充 `NaN`。\n",
    "#   - 适合用统计值（如均值、中位数）填充缺失值。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0    1.000000\n",
    "1    3.833333\n",
    "2    3.500000\n",
    "3    3.833333\n",
    "4    7.000000\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ce9f5",
   "metadata": {},
   "source": [
    "### 7.3 本节重点\n",
    "- **检测缺失值**:\n",
    "  - `isnull()` 和 `notnull()` 返回布尔Series，分别标识缺失和非缺失值。\n",
    "  - 可用于筛选或条件判断。\n",
    "- **过滤缺失值**:\n",
    "  - `dropna()` 删除包含缺失值的行或列，默认删除任何缺失值的行。\n",
    "  - `how=\"all\"` 仅删除全为缺失值的行/列，`thresh` 指定非缺失值的最小数量。\n",
    "  - 支持 `axis` 参数，灵活选择操作方向。\n",
    "- **填充缺失值**:\n",
    "  - `fillna(value)` 用指定值（如0）填充 `NaN`。\n",
    "  - `fillna(dict)` 为不同列指定不同填充值。\n",
    "  - `method=\"ffill\"` 或 `method=\"bfill\"` 使用前向或后向填充。\n",
    "  - `fillna(data.mean())` 用统计值填充，适合数值数据。\n",
    "- **注意事项**:\n",
    "  - 缺失值处理需根据数据场景选择方法（如删除 vs. 填充）。\n",
    "  - `dropna()` 和 `fillna()` 默认返回新对象，需赋值或使用 `inplace=True` 修改原对象。\n",
    "  - 前向/后向填充对时间序列数据特别有用，但需确保数据顺序合理。\n",
    "  - 较新版本pandas推荐使用 `ffill()` 和 `bfill()` 方法替代 `method` 参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae4b67",
   "metadata": {},
   "source": [
    "## 数据转换 (页码: p204)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f0fe05",
   "metadata": {},
   "source": [
    "## 8. 数据转换\n",
    "#### 页码: p204\n",
    "\n",
    "### 8.1 章节概述\n",
    "本节介绍了pandas中用于数据转换的方法，包括移除重复数据、数据映射、替换值、离散化（分箱）以及排列和随机采样。这些操作是数据清洗和预处理的重要步骤，旨在将原始数据转换为适合分析的格式。本节强调了灵活性和高效性，特别是在处理大规模数据集时。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79543f",
   "metadata": {},
   "source": [
    "### 8.2 代码与注释\n",
    "\n",
    "#### 8.2.1 移除重复数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52807bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"k1\": [\"one\", \"two\"] * 3 + [\"two\"],\n",
    "                     \"k2\": [1, 1, 2, 3, 3, 4, 4]})\n",
    "data\n",
    "\n",
    "# - **注释**:\n",
    "#   - 创建一个DataFrame，包含两列（`k1`, `k2`），第6行（`two`, 4）与第5行重复。\n",
    "#   - 重复数据可能源于数据录入错误或合并操作。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "    k1  k2\n",
    "0  one   1\n",
    "1  two   1\n",
    "2  one   2\n",
    "3  two   3\n",
    "4  one   3\n",
    "5  two   4\n",
    "6  two   4\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38b5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `duplicated()` 检查每行是否为重复行（与之前的行完全相同），返回布尔Series。\n",
    "#   - 第6行与第5行相同，标记为 `True`.\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0    False\n",
    "1    False\n",
    "2    False\n",
    "3    False\n",
    "4    False\n",
    "5    False\n",
    "6     True\n",
    "dtype: bool\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515cd495",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `drop_duplicates()` 删除重复行，保留第一次出现的行（默认）。\n",
    "#   - 第6行被移除，返回新DataFrame。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "    k1  k2\n",
    "0  one   1\n",
    "1  two   1\n",
    "2  one   2\n",
    "3  two   3\n",
    "4  one   3\n",
    "5  two   4\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17021a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"v1\"] = range(7)\n",
    "data\n",
    "data.drop_duplicates(subset=[\"k1\"])\n",
    "\n",
    "# - **注释**:\n",
    "#   - 添加新列 `v1`，值为0到6。\n",
    "#   - `drop_duplicates(subset=[\"k1\"])` 仅根据 `k1` 列检查重复，保留第一次出现的行。\n",
    "#   - 结果保留 `k1` 为 `\"one\"` 和 `\"two\"` 的最早行。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "    k1  k2  v1\n",
    "0  one   1   0\n",
    "1  two   1   1\n",
    "2  one   2   2\n",
    "3  two   3   3\n",
    "4  one   3   4\n",
    "5  two   4   5\n",
    "6  two   4   6\n",
    "\n",
    "    k1  k2  v1\n",
    "0  one   1   0\n",
    "1  two   1   1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e25e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates([\"k1\", \"k2\"], keep=\"last\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `drop_duplicates([\"k1\", \"k2\"], keep=\"last\")` 根据 `k1` 和 `k2` 组合检查重复，保留最后出现的行。\n",
    "#   - 第5行被移除（因与第6行重复），第6行保留。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "    k1  k2  v1\n",
    "0  one   1   0\n",
    "1  two   1   1\n",
    "2  one   2   2\n",
    "3  two   3   3\n",
    "4  one   3   4\n",
    "6  two   4   6\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35f3bc",
   "metadata": {},
   "source": [
    "#### 8.2.2 使用函数或映射转换数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"food\": [\"bacon\", \"pulled pork\", \"bacon\",\n",
    "                              \"pastrami\", \"corned beef\", \"bacon\",\n",
    "                              \"pastrami\", \"honey ham\", \"nova lox\"],\n",
    "                     \"ounces\": [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "data\n",
    "\n",
    "# - **注释**:\n",
    "#   - 创建一个DataFrame，包含食物名称（`food`）和重量（`ounces`）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "          food  ounces\n",
    "0        bacon     4.0\n",
    "1  pulled pork     3.0\n",
    "2        bacon    12.0\n",
    "3     pastrami     6.0\n",
    "4  corned beef     7.5\n",
    "5        bacon     8.0\n",
    "6     pastrami     3.0\n",
    "7    honey ham     5.0\n",
    "8     nova lox     6.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e987de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_to_animal = {\n",
    "    \"bacon\": \"pig\",\n",
    "    \"pulled pork\": \"pig\",\n",
    "    \"pastrami\": \"cow\",\n",
    "    \"corned beef\": \"cow\",\n",
    "    \"honey ham\": \"pig\",\n",
    "    \"nova lox\": \"salmon\"\n",
    "}\n",
    "\n",
    "# - **注释**:\n",
    "#   - 定义字典 `meat_to_animal`，将食物映射到对应的动物来源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d32140",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"animal\"] = data[\"food\"].map(meat_to_animal)\n",
    "data\n",
    "\n",
    "# - **注释**:\n",
    "#   - `map()` 对 `food` 列的每个值应用字典映射，添加新列 `animal`。\n",
    "#   - 每个食物名称被替换为其对应的动物来源。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "          food  ounces  animal\n",
    "0        bacon     4.0     pig\n",
    "1  pulled pork     3.0     pig\n",
    "2        bacon    12.0     pig\n",
    "3     pastrami     6.0     cow\n",
    "4  corned beef     7.5     cow\n",
    "5        bacon     8.0     pig\n",
    "6     pastrami     3.0     cow\n",
    "7    honey ham     5.0     pig\n",
    "8     nova lox     6.0  salmon\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6667061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_animal(x):\n",
    "    return meat_to_animal[x]\n",
    "data[\"food\"].map(get_animal)\n",
    "\n",
    "# - **注释**:\n",
    "#   - 定义函数 `get_animal`，实现与字典相同的映射逻辑。\n",
    "#   - `map(get_animal)` 对 `food` 列应用函数，返回映射后的Series。\n",
    "#   - 功能与直接使用字典相同，但函数更灵活。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0       pig\n",
    "1       pig\n",
    "2       pig\n",
    "3       cow\n",
    "4       cow\n",
    "5       pig\n",
    "6       cow\n",
    "7       pig\n",
    "8    salmon\n",
    "Name: food, dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb74e1",
   "metadata": {},
   "source": [
    "#### 8.2.3 替换值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb317cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([1., -999., 2., -999., -1000., 3.])\n",
    "data\n",
    "\n",
    "# - **注释**:\n",
    "#   - 创建一个Series，包含异常值（如 -999, -1000），可能表示缺失值。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0       1.0\n",
    "1    -999.0\n",
    "2       2.0\n",
    "3    -999.0\n",
    "4   -1000.0\n",
    "5       3.0\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e85135",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(-999, np.nan)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `replace(-999, np.nan)` 将 -999 替换为 `NaN`。\n",
    "#   - 返回新Series，原对象不变。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0       1.0\n",
    "1       NaN\n",
    "2       2.0\n",
    "3       NaN\n",
    "4   -1000.0\n",
    "5       3.0\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4deb238",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([-999, -1000], np.nan)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `replace([old_values], new_value)` 同时替换多个值（-999, -1000）为 `NaN`。\n",
    "#   - 适合批量处理异常值。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0    1.0\n",
    "1    NaN\n",
    "2    2.0\n",
    "3    NaN\n",
    "4    NaN\n",
    "5    3.0\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75afea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([-999, -1000], [np.nan, 0])\n",
    "\n",
    "# - **注释**:\n",
    "#   - `replace([old_values], [new_values])` 为不同旧值指定不同新值（-999 → `NaN`, -1000 → 0）。\n",
    "#   - 提供更细粒度的替换控制。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0    1.0\n",
    "1    NaN\n",
    "2    2.0\n",
    "3    NaN\n",
    "4    0.0\n",
    "5    3.0\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca62485",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace({-999: np.nan, -1000: 0})\n",
    "\n",
    "# - **注释**:\n",
    "#   - `replace(dict)` 使用字典指定替换规则，等效于上例。\n",
    "#   - 字典形式更直观，适合复杂替换。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "0    1.0\n",
    "1    NaN\n",
    "2    2.0\n",
    "3    NaN\n",
    "4    0.0\n",
    "5    3.0\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acffa682",
   "metadata": {},
   "source": [
    "#### 8.2.4 重命名轴索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725419d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)),\n",
    "                    index=[\"Ohio\", \"Colorado\", \"New York\"],\n",
    "                    columns=[\"one\", \"two\", \"three\", \"four\"])\n",
    "data\n",
    "\n",
    "# - **注释**:\n",
    "#   - 创建3x4的DataFrame，行索引为州名，列名为数字。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "          one  two  three  four\n",
    "Ohio        0    1      2     3\n",
    "Colorado    4    5      6     7\n",
    "New York    8    9     10    11\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a14309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    return x[:4].upper()\n",
    "data.index.map(transform)\n",
    "\n",
    "# - **注释**:\n",
    "#   - 定义函数 `transform`，将字符串前4个字符转换为大写。\n",
    "#   - `index.map(transform)` 对行索引应用函数，返回新Index对象。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Index(['OHIO', 'COLO', 'NEW '], dtype='object')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2123d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = data.index.map(transform)\n",
    "data\n",
    "\n",
    "# - **注释**:\n",
    "#   - 将转换后的索引赋值给 `data.index`，修改原DataFrame的行索引。\n",
    "#   - 新索引为 `\"OHIO\", \"COLO\", \"NEW \"`。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "      one  two  three  four\n",
    "OHIO    0    1      2     3\n",
    "COLO    4    5      6     7\n",
    "NEW     8    9     10    11\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ee952",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(index=str.title, columns=str.upper)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `rename(index=str.title, columns=str.upper)` 对行索引应用标题格式（首字母大写），对列名应用全大写。\n",
    "#   - 返回新DataFrame，原对象不变。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "      ONE  TWO  THREE  FOUR\n",
    "Ohio    0    1      2     3\n",
    "Colo    4    5      6     7\n",
    "New     8    9     10    11\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69caca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(index={\"OHIO\": \"INDIANA\"},\n",
    "            columns={\"three\": \"peekaboo\"})\n",
    "\n",
    "# - **注释**:\n",
    "#   - `rename(index=dict, columns=dict)` 使用字典指定特定索引/列名的替换。\n",
    "#   - 例如，将 `\"OHIO\"` 改为 `\"INDIANA\"`，`\"three\"` 改为 `\"peekaboo\"`。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "          one  two  peekaboo  four\n",
    "INDIANA     0    1         2     3\n",
    "COLO        4    5         6     7\n",
    "NEW         8    9        10    11\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ce8b7",
   "metadata": {},
   "source": [
    "#### 8.2.5 离散化和分箱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3467ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]\n",
    "bins = [18, 25, 35, 60, 100]\n",
    "age_categories = pd.cut(ages, bins)\n",
    "age_categories\n",
    "\n",
    "# - **注释**:\n",
    "#   - `pd.cut(ages, bins)` 将 `ages` 分到指定区间（`bins`），返回Categorical对象。\n",
    "#   - 区间为 `(18, 25]`, `(25, 35]`, `(35, 60]`, `(60, 100]`，右闭合（包含右端点）。\n",
    "#   - 每个年龄被分配到对应区间。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "[(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35, 60], (35, 60], (25, 35]]\n",
    "Categories (4, interval[int64, right]): [(18, 25] < (25, 35] < (35, 60] < (60, 100]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b0923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_categories.codes\n",
    "age_categories.categories\n",
    "pd.value_counts(age_categories)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `codes` 返回每个年龄所属区间的整数编码（0到3）。\n",
    "#   - `categories` 返回区间列表。\n",
    "#   - `pd.value_counts(age_categories)` 统计每个区间的频率。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "array([0, 0, 0, 1, 0, 0, 2, 1, 3, 2, 2, 1], dtype=int8)\n",
    "\n",
    "IntervalIndex([(18, 25], (25, 35], (35, 60], (60, 100]], dtype='interval[int64, right]')\n",
    "\n",
    "(18, 25]     5\n",
    "(25, 35]     4\n",
    "(35, 60]     2\n",
    "(60, 100]    1\n",
    "dtype: int64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76458975",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(ages, [18, 26, 36, 61, 100], right=False)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `right=False` 使区间左闭右开（如 `[18, 26)`）。\n",
    "#   - 区间变为 `[18, 26)`, `[26, 36)`, `[36, 61)`, `[61, 100)`。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "[[18, 26), [18, 26), [18, 26), [26, 36), [18, 26), ..., [26, 36), [61, 100), [36, 61), [36, 61), [26, 36)]\n",
    "Categories (4, interval[int64, left]): [[18, 26) < [26, 36) < [36, 61) < [61, 100)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95433f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = [\"Youth\", \"YoungAdult\", \"MiddleAged\", \"Senior\"]\n",
    "pd.cut(ages, bins, labels=group_names)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `labels=group_names` 为每个区间指定名称（`Youth`, `YoungAdult`, `MiddleAged`, `Senior`）。\n",
    "#   - 返回的Categorical对象使用自定义标签而非区间。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "['Youth', 'Youth', 'Youth', 'YoungAdult', 'Youth', ..., 'YoungAdult', 'Senior', 'MiddleAged', 'MiddleAged', 'YoungAdult']\n",
    "Categories (4, object): ['Youth' < 'YoungAdult' < 'MiddleAged' < 'Senior']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4a6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.uniform(size=20)\n",
    "pd.cut(data, 4, precision=2)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `pd.cut(data, 4)` 将均匀分布的随机数分为4个等宽区间。\n",
    "#   - `precision=2` 限制区间边界的小数位数为2位。\n",
    "#   - 区间宽度由数据范围自动计算。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "[(0.34, 0.55], (0.34, 0.55], (0.76, 0.97], (0.55, 0.76], ..., (0.34, 0.55]]\n",
    "Categories (4, interval[float64, right]): [(0.12, 0.34] < (0.34, 0.55] < (0.55, 0.76] < (0.76, 0.97]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.standard_normal(1000)\n",
    "quartiles = pd.qcut(data, 4, precision=2)\n",
    "quartiles\n",
    "pd.value_counts(quartiles)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `pd.qcut(data, 4)` 将数据分为4个等频分位数区间（每组约250个数据点）。\n",
    "#   - `precision=2` 控制边界精度。\n",
    "#   - `pd.value_counts(quartiles)` 确认每个区间的数据点数量相等。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "[(-0.68, 0.03], (-3.28, -0.68], (0.68, 3.56], (-0.68, 0.03], ..., (-0.68, 0.03]]\n",
    "Categories (4, interval[float64, right]): [(-3.28, -0.68] < (-0.68, 0.03] < (0.03, 0.68] < (0.68, 3.56]]\n",
    "\n",
    "(-3.28, -0.68]    250\n",
    "(-0.68, 0.03]      250\n",
    "(0.03, 0.68]       250\n",
    "(0.68, 3.56]       250\n",
    "dtype: int64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e559ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(data, [0, 0.1, 0.5, 0.9, 1.], labels=False)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `pd.qcut(data, [0, 0.1, 0.5, 0.9, 1.])` 按指定分位数（10%、50%、90%）分箱。\n",
    "#   - `labels=False` 返回整数编码（0到3），而非区间或标签。\n",
    "#   - 适合需要分位数编码的场景。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "array([2, 0, 3, 1, ..., 2], dtype=int64)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d045f6e",
   "metadata": {},
   "source": [
    "#### 8.2.6 检测和过滤异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ecbc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.random.standard_normal((1000, 4)))\n",
    "data.describe()\n",
    "\n",
    "# - **注释**:\n",
    "#   - 创建1000x4的DataFrame，包含标准正态分布的随机数。\n",
    "#   - `describe()` 显示每列的统计信息，用于初步检查数据分布。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "                0            1            2            3\n",
    "count  1000.000000  1000.000000  1000.000000  1000.000000\n",
    "mean     -0.002297     0.015981    -0.000234    -0.005058\n",
    "std       0.996157     1.003668     0.999085     1.002086\n",
    "min      -3.547589    -3.260392    -3.693649    -3.536360\n",
    "25%      -0.672329    -0.657929    -0.674805    -0.685242\n",
    "50%       0.002060     0.018599     0.001165    -0.005346\n",
    "75%       0.669099     0.691717     0.669805     0.669652\n",
    "max       3.366626     3.396692     3.896904     3.391050\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d41a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = data[2]\n",
    "col[col.abs() > 3]\n",
    "\n",
    "# - **注释**:\n",
    "#   - `col.abs() > 3` 筛选第2列中绝对值大于3的异常值。\n",
    "#   - 返回符合条件的Series，显示异常值的索引和值。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "234   -3.693649\n",
    "433    3.896904\n",
    "Name: 2, dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data.abs() > 3).any(axis=\"columns\")]\n",
    "\n",
    "# - **注释**:\n",
    "#   - `(data.abs() > 3).any(axis=\"columns\")` 检查每行是否至少有一个值绝对值大于3。\n",
    "#   - 返回包含异常值的行，适合检测整个DataFrame的异常。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "           0         1         2         3\n",
    "234  -0.567234 -0.345678 -3.693649  0.123456\n",
    "433   0.789012  0.234567  3.896904 -0.456789\n",
    "567  -3.547589  0.678901  0.234567  0.789012\n",
    "...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531adb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.abs() > 3] = np.sign(data) * 3\n",
    "data.describe()\n",
    "\n",
    "# - **注释**:\n",
    "#   - `data.abs() > 3` 标识绝对值大于3的值。\n",
    "#   - `np.sign(data) * 3` 将这些值替换为 ±3（保留原值的符号）。\n",
    "#   - `describe()` 确认最大/最小值被限制在 ±3。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "                0            1            2            3\n",
    "count  1000.000000  1000.000000  1000.000000  1000.000000\n",
    "mean     -0.002297     0.015981    -0.000234    -0.005058\n",
    "std       0.996157     1.003668     0.999085     1.002086\n",
    "min      -3.000000    -3.000000    -3.000000    -3.000000\n",
    "25%      -0.672329    -0.657929    -0.674805    -0.685242\n",
    "50%       0.002060     0.018599     0.001165    -0.005346\n",
    "75%       0.669099     0.691717     0.669805     0.669652\n",
    "max       3.000000     3.000000     3.000000     3.000000\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add1259f",
   "metadata": {},
   "source": [
    "#### 8.2.7 排列和随机采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(5 * 7).reshape((5, 7)))\n",
    "df\n",
    "\n",
    "# - **注释**:\n",
    "#   - 创建5x7的DataFrame，值为0到34。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   0   1   2   3   4   5   6\n",
    "0   0   1   2   3   4   5   6\n",
    "1   7   8   9  10  11  12  13\n",
    "2  14  15  16  17  18  19  20\n",
    "3  21  22  23  24  25  26  27\n",
    "4  28  29  30  31  32  33  34\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975e53d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = np.random.permutation(5)\n",
    "sampler\n",
    "\n",
    "# - **注释**:\n",
    "#   - `np.random.permutation(5)` 生成0到4的随机排列。\n",
    "#   - 用于打乱行索引顺序。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "array([3, 1, 4, 0, 2])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9dfe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.take(sampler)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `take(sampler)` 按 `sampler` 的顺序重新排列行。\n",
    "#   - 结果DataFrame的行顺序被随机打乱。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   0   1   2   3   4   5   6\n",
    "3  21  22  23  24  25  26  27\n",
    "1   7   8   9  10  11  12  13\n",
    "4  28  29  30  31  32  33  34\n",
    "0   0   1   2   3   4   5   6\n",
    "2  14  15  16  17  18  19  20\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd100e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[sampler]\n",
    "\n",
    "# - **注释**:\n",
    "#   - `iloc[sampler]` 等效于 `take(sampler)`，按指定顺序选择行。\n",
    "#   - `iloc` 更直观，推荐使用。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   0   1   2   3   4   5   6\n",
    "3  21  22  23  24  25  26  27\n",
    "1   7   8   9  10  11  12  13\n",
    "4  28  29  30  31  32  33  34\n",
    "0   0   1   2   3   4   5   6\n",
    "2  14  15  16  17  18  19  20\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = pd.Series([5, 7, -1, 6, 4])\n",
    "choices.sample(n=10, replace=True)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `sample(n=10, replace=True)` 从Series中随机抽样10个值，允许重复（有放回抽样）。\n",
    "#   - 结果可能包含重复值，适合模拟或生成随机数据。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "2   -1\n",
    "4    4\n",
    "1    7\n",
    "0    5\n",
    "3    6\n",
    "2   -1\n",
    "4    4\n",
    "1    7\n",
    "0    5\n",
    "2   -1\n",
    "dtype: int64\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a2156",
   "metadata": {},
   "source": [
    "### 8.3 本节重点\n",
    "- **移除重复数据**:\n",
    "  - `duplicated()` 检测重复行，`drop_duplicates()` 删除重复行。\n",
    "  - 支持 `subset` 指定检查的列，`keep=\"first\"/\"last\"` 控制保留的行。\n",
    "- **数据映射**:\n",
    "  - `map()` 对Series应用字典或函数进行转换，适合列级操作。\n",
    "  - 可用于添加新列或转换现有值。\n",
    "- **替换值**:\n",
    "  - `replace()` 替换指定值，支持单值、列表或字典形式。\n",
    "  - 常用于处理异常值或标准化数据。\n",
    "- **重命名轴索引**:\n",
    "  - `index.map()` 或 `rename()` 修改行/列索引，支持函数或字典。\n",
    "  - `rename()` 更灵活，可同时处理行和列。\n",
    "- **离散化和分箱**:\n",
    "  - `pd.cut()` 按指定区间分箱，`pd.qcut()` 按分位数分箱。\n",
    "  - 支持自定义标签、精度和开闭区间。\n",
    "  - 适合将连续值转为分类变量。\n",
    "- **异常值处理**:\n",
    "  - 使用布尔索引（如 `abs() > 3`）检测异常值。\n",
    "  - 可通过赋值（如 `np.sign(data) * 3`）限制异常值范围。\n",
    "- **排列和采样**:\n",
    "  - `np.random.permutation()` 和 `take()`/`iloc` 实现随机重排。\n",
    "  - `sample()` 进行随机抽样，支持有放回或无放回。\n",
    "- **注意事项**:\n",
    "  - 大多数操作（如 `drop_duplicates()`, `replace()`, `rename()`) 返回新对象，需赋值或使用 `inplace=True`。\n",
    "  - 分箱和异常值处理需根据数据分布选择合适方法。\n",
    "  - 随机操作（如 `sample()`, `permutation()`) 结果随机，需设置种子以确保可重复性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8606f2c",
   "metadata": {},
   "source": [
    "## 计算指标/虚拟变量 (页码: p211)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23dd757",
   "metadata": {},
   "source": [
    "## 9. 计算指标/虚拟变量\n",
    "#### 页码: p211\n",
    "\n",
    "### 9.1 章节概述\n",
    "本节介绍了如何在pandas中创建指标变量（也称为虚拟变量，dummy variables）以及计算其他衍生变量。虚拟变量常用于将分类数据转换为适合机器学习模型的二进制（0/1）表示。此外，本节还展示了如何结合分组操作生成复杂的指标变量，以及处理多类别数据和高维虚拟变量矩阵的场景。这些方法在数据预处理和特征工程中尤为重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23df6df3",
   "metadata": {},
   "source": [
    "### 9.2 代码与注释\n",
    "\n",
    "#### 9.2.1 创建虚拟变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"b\"],\n",
    "                   \"data1\": range(6)})\n",
    "df\n",
    "\n",
    "# - **注释**:\n",
    "#   - 创建一个DataFrame，包含分类列 `key`（值为 `\"a\"`, `\"b\"`, `\"c\"`）和数值列 `data1`。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "  key  data1\n",
    "0   b      0\n",
    "1   b      1\n",
    "2   a      2\n",
    "3   c      3\n",
    "4   a      4\n",
    "5   b      5\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df[\"key\"])\n",
    "\n",
    "# - **注释**:\n",
    "#   - `pd.get_dummies(df[\"key\"])` 将 `key` 列的分类值转换为虚拟变量矩阵。\n",
    "#   - 每列对应一个唯一类别（`a`, `b`, `c`），值为1表示该行属于该类别，0表示不属于。\n",
    "#   - 返回新的DataFrame，列名为类别值。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   a  b  c\n",
    "0  0  1  0\n",
    "1  0  1  0\n",
    "2  1  0  0\n",
    "3  0  0  1\n",
    "4  1  0  0\n",
    "5  0  1  0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a5b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df[\"key\"], prefix=\"key\")\n",
    "dummies\n",
    "\n",
    "# - **注释**:\n",
    "#   - `prefix=\"key\"` 为虚拟变量的列名添加前缀（`key_a`, `key_b`, `key_c`）。\n",
    "#   - 有助于区分多个分类列的虚拟变量。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   key_a  key_b  key_c\n",
    "0      0      1      0\n",
    "1      0      1      0\n",
    "2      1      0      0\n",
    "3      0      0      1\n",
    "4      1      0      0\n",
    "5      0      1      0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feedf16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummy = df[[\"data1\"]].join(dummies)\n",
    "df_with_dummy\n",
    "\n",
    "# - **注释**:\n",
    "#   - `df[[\"data1\"]].join(dummies)` 将虚拟变量矩阵与 `data1` 列合并。\n",
    "#   - `join()` 默认按索引对齐，生成包含原始数据和虚拟变量的新DataFrame。\n",
    "#   - 适用于机器学习特征矩阵的构建。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   data1  key_a  key_b  key_c\n",
    "0      0      0      1      0\n",
    "1      1      0      1      0\n",
    "2      2      1      0      0\n",
    "3      3      0      0      1\n",
    "4      4      1      0      0\n",
    "5      5      0      1      0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298d6f0",
   "metadata": {},
   "source": [
    "#### 9.2.2 处理多类别数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43db3b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnames = [\"movie_id\", \"title\", \"genres\"]\n",
    "movies = pd.read_table(\"datasets/movielens/movies.dat\", sep=\"::\",\n",
    "                       header=None, names=mnames, engine=\"python\")\n",
    "movies[:10]\n",
    "\n",
    "# - **注释**:\n",
    "#   - 从 `movies.dat` 文件读取电影数据，包含 `movie_id`, `title`, 和 `genres` 列。\n",
    "#   - `genres` 列包含多类别值（用 `|` 分隔，如 `Animation|Children's|Comedy`）。\n",
    "#   - `engine=\"python\"` 解决分隔符解析问题。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   movie_id                               title                        genres\n",
    "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
    "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
    "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
    "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
    "4         5  Father of the Bride Part II (1995)                        Comedy\n",
    "5         6                         Heat (1995)         Action|Crime|Thriller\n",
    "6         7                      Sabrina (1995)                Comedy|Romance\n",
    "7         8                 Tom and Huck (1995)      Adventure|Children's\n",
    "8         9                 Sudden Death (1995)                        Action\n",
    "9        10                    GoldenEye (1995)     Action|Adventure|Thriller\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad630103",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = []\n",
    "for x in movies.genres:\n",
    "    all_genres.extend(x.split(\"|\"))\n",
    "genres = pd.unique(all_genres)\n",
    "genres\n",
    "\n",
    "# - **注释**:\n",
    "#   - 遍历 `genres` 列，将每个电影的类型（用 `|` 分隔）拆分为列表。\n",
    "#   - `extend()` 将拆分后的类型添加到 `all_genres`。\n",
    "#   - `pd.unique()` 获取所有唯一的电影类型（18种）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "array(['Animation', \"Children's\", 'Comedy', 'Adventure', 'Fantasy',\n",
    "       'Romance', 'Drama', 'Action', 'Crime', 'Thriller', 'Horror',\n",
    "       'Sci-Fi', 'Documentary', 'War', 'Musical', 'Mystery', 'Film-Noir',\n",
    "       'Western'], dtype=object)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc7e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_matrix = np.zeros((len(movies), len(genres)))\n",
    "dummies = pd.DataFrame(zero_matrix, columns=genres)\n",
    "dummies\n",
    "\n",
    "# - **注释**:\n",
    "#   - 创建一个形状为 `(电影数量, 类型数量)` 的零矩阵。\n",
    "#   - 转换为DataFrame，列名为所有唯一类型（`genres`）。\n",
    "#   - 用于存储每部电影的虚拟变量。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   Animation  Children's  Comedy  ...  Mystery  Film-Noir  Western\n",
    "0        0.0         0.0     0.0  ...      0.0        0.0      0.0\n",
    "1        0.0         0.0     0.0  ...      0.0        0.0      0.0\n",
    "...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39147415",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, gen in enumerate(movies.genres):\n",
    "    indices = dummies.columns.get_indexer(gen.split(\"|\"))\n",
    "    dummies.iloc[i, indices] = 1\n",
    "dummies\n",
    "\n",
    "# - **注释**:\n",
    "#   - 遍历每部电影的 `genres` 值，拆分为类型列表。\n",
    "#   - `get_indexer()` 获取每个类型在 `dummies` 列中的索引。\n",
    "#   - 将对应位置设为1，表示该电影属于该类型。\n",
    "#   - 结果是每部电影的虚拟变量矩阵。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   Animation  Children's  Comedy  ...  Mystery  Film-Noir  Western\n",
    "0        1.0         1.0     1.0  ...      0.0        0.0      0.0\n",
    "1        0.0         1.0     0.0  ...      0.0        0.0      0.0\n",
    "...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9879c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_windic = movies.join(dummies.add_prefix(\"Genre_\"))\n",
    "movies_windic.iloc[0]\n",
    "\n",
    "# - **注释**:\n",
    "#   - `dummies.add_prefix(\"Genre_\")` 为虚拟变量列添加前缀（`Genre_Animation` 等）。\n",
    "#   - `movies.join()` 将虚拟变量矩阵与原始 `movies` 数据合并。\n",
    "#   - `iloc[0]` 显示第一部电影的完整信息，包括虚拟变量。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "movie_id                                       1\n",
    "title                           Toy Story (1995)\n",
    "genres               Animation|Children's|Comedy\n",
    "Genre_Animation                              1.0\n",
    "Genre_Children's                             1.0\n",
    "Genre_Comedy                                 1.0\n",
    "...\n",
    "Genre_Western                                0.0\n",
    "Name: 0, dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d54fe",
   "metadata": {},
   "source": [
    "#### 9.2.3 结合分箱生成虚拟变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df1e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "values = np.random.uniform(size=10)\n",
    "values\n",
    "\n",
    "# - **注释**:\n",
    "#   - 设置随机种子确保可重复性。\n",
    "#   - 生成10个均匀分布的随机数（0到1之间）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "array([0.92961609, 0.31637555, 0.18391881, 0.20456028, 0.56772503,\n",
    "       0.5955447 , 0.96451452, 0.6531771 , 0.74890664, 0.65356987])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10229fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "pd.get_dummies(pd.cut(values, bins))\n",
    "\n",
    "# - **注释**:\n",
    "#   - `pd.cut(values, bins)` 将 `values` 分箱到指定区间（`(0, 0.2]`, `(0.2, 0.4]`, 等）。\n",
    "#   - `pd.get_dummies()` 将分箱结果转换为虚拟变量矩阵。\n",
    "#   - 每列对应一个区间，1表示该值落入该区间，0表示未落入。\n",
    "#   - 适用于将连续值离散化后生成特征。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "   (0.0, 0.2]  (0.2, 0.4]  (0.4, 0.6]  (0.6, 0.8]  (0.8, 1.0]\n",
    "0           0           0           0           0           1\n",
    "1           0           1           0           0           0\n",
    "2           1           0           0           0           0\n",
    "3           0           1           0           0           0\n",
    "4           0           0           1           0           0\n",
    "5           0           0           1           0           0\n",
    "6           0           0           0           0           1\n",
    "7           0           0           0           1           0\n",
    "8           0           0           0           1           0\n",
    "9           0           0           0           1           0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c78cceb",
   "metadata": {},
   "source": [
    "### 9.3 本节重点\n",
    "- **创建虚拟变量**:\n",
    "  - `pd.get_dummies()` 将分类列转换为二进制虚拟变量矩阵。\n",
    "  - `prefix` 参数添加列名前缀，`join()` 合并到原始数据。\n",
    "  - 常用于机器学习模型的特征编码。\n",
    "- **处理多类别数据**:\n",
    "  - 对于多类别列（如电影类型），需拆分类别并手动构建虚拟变量矩阵。\n",
    "  - 使用 `get_indexer()` 和 `iloc` 设置虚拟变量值。\n",
    "  - `add_prefix()` 和 `join()` 整合结果，适合复杂数据集。\n",
    "- **结合分箱生成虚拟变量**:\n",
    "  - `pd.cut()` 分箱后结合 `pd.get_dummies()` 生成虚拟变量。\n",
    "  - 适用于将连续变量转为分类特征。\n",
    "- **注意事项**:\n",
    "  - 虚拟变量矩阵可能高维（类别数多时），需考虑稀疏矩阵或降维。\n",
    "  - 多类别处理需确保类别拆分准确，避免遗漏或重复。\n",
    "  - 分箱时需合理选择区间边界，以反映数据分布。\n",
    "  - `get_dummies()` 默认对所有唯一值编码，需检查数据清洗是否完整。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b83f3c",
   "metadata": {},
   "source": [
    "## 字符串操作 (页码: p213)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25f1def",
   "metadata": {},
   "source": [
    "## 10. 字符串操作\n",
    "#### 页码: p213\n",
    "\n",
    "### 10.1 章节概述\n",
    "本节介绍了Python和pandas中处理字符串数据的方法，包括Python内置字符串方法、pandas的矢量化字符串操作以及正则表达式。字符串操作在数据清洗中至关重要，例如提取、拆分、替换或格式化文本数据。本节强调了pandas的字符串方法如何高效处理Series和DataFrame中的文本数据，特别是结合正则表达式进行复杂模式匹配。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a29c69",
   "metadata": {},
   "source": [
    "### 10.2 代码与注释\n",
    "\n",
    "#### 10.2.1 Python内置字符串方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = \"a,b,  guido\"\n",
    "val.split(\",\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `split(\",\")` 以逗号分隔字符串，返回列表。\n",
    "#   - 结果包含空格（如 `'  guido'`），需进一步处理。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "['a', 'b', '  guido']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de500586",
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = [x.strip() for x in val.split(\",\")]\n",
    "pieces\n",
    "\n",
    "# - **注释**:\n",
    "#   - `strip()` 去除每个元素两端的空白字符。\n",
    "#   - 列表推导式对 `split()` 结果逐个应用 `strip()`，清理空格。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "['a', 'b', 'guido']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e4dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "first, second, third = pieces\n",
    "first + \"::\" + second + \"::\" + third\n",
    "\n",
    "# - **注释**:\n",
    "#   - 解包 `pieces` 列表到变量 `first`, `second`, `third`。\n",
    "#   - 使用 `+` 拼接字符串，插入 `::` 分隔符。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "'a::b::guido'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b682ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"::\".join(pieces)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `join()` 更高效地将列表元素拼接为字符串，使用 `::` 作为分隔符。\n",
    "#   - 比手动拼接更简洁，推荐使用。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "'a::b::guido'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7419783",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"guido\" in val\n",
    "val.index(\",\")\n",
    "val.find(\":\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `\"guido\" in val` 检查子字符串是否存在，返回 `True`。\n",
    "#   - `index(\",\")` 返回第一个逗号的索引（1），若不存在则抛出异常。\n",
    "#   - `find(\":\")` 返回第一个冒号的索引，若不存在返回 -1（更安全）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "True\n",
    "1\n",
    "-1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67314078",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.count(\",\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `count(\",\")` 返回逗号出现的次数（2次）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.replace(\",\", \"::\")\n",
    "val.replace(\",\", \"\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `replace(\",\", \"::\")` 将逗号替换为 `::`。\n",
    "#   - `replace(\",\", \"\")` 删除所有逗号。\n",
    "#   - 返回新字符串，原字符串不变。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "'a::b::  guido'\n",
    "'ab  guido'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47af9179",
   "metadata": {},
   "source": [
    "#### 10.2.2 正则表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0413fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"foo    bar\\t baz  \\tqux\"\n",
    "re.split(r\"\\s+\", text)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `re.split(r\"\\s+\", text)` 使用正则表达式 `\\s+`（一个或多个空白字符）分割字符串。\n",
    "#   - 能处理多种空白字符（空格、制表符等），比 `split()` 更灵活。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "['foo', 'bar', 'baz', 'qux']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548fd430",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r\"\\s+\")\n",
    "regex.split(text)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `re.compile(r\"\\s+\")` 预编译正则表达式，提高重复使用的效率。\n",
    "#   - `regex.split(text)` 与直接 `re.split()` 效果相同，但性能更优。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "['foo', 'bar', 'baz', 'qux']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f47b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex.findall(text)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `findall()` 返回匹配正则表达式 `\\s+` 的所有子字符串（即空白字符序列）。\n",
    "#   - 常用于检查或提取匹配模式。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "['    ', '\\t ', '  \\t']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Dave dave@google.com\n",
    "Steve steve@gmail.com\n",
    "Rob rob@gmail.com\n",
    "Ryan ryan@yahoo.com\"\"\"\n",
    "pattern = r\"[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}\"\n",
    "regex = re.compile(pattern, flags=re.IGNORECASE)\n",
    "regex.findall(text)\n",
    "\n",
    "# - **注释**:\n",
    "#   - 定义正则表达式 `pattern` 匹配电子邮件地址：\n",
    "#     - `[A-Z0-9._%+-]+`：用户名部分（字母、数字、特定符号）。\n",
    "#     - `@`：@符号。\n",
    "#     - `[A-Z0-9.-]+`：域名部分。\n",
    "#     - `\\.[A-Z]{2,4}`：顶级域名（2-4个字母）。\n",
    "#   - `flags=re.IGNORECASE` 忽略大小写。\n",
    "#   - `findall()` 提取所有匹配的邮箱地址。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "['dave@google.com', 'steve@gmail.com', 'rob@gmail.com', 'ryan@yahoo.com']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60efafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = regex.search(text)\n",
    "m\n",
    "text[m.start():m.end()]\n",
    "\n",
    "# - **注释**:\n",
    "#   - `search()` 返回第一个匹配的正则表达式对象（包含位置信息）。\n",
    "#   - `m.start()` 和 `m.end()` 获取匹配的起始和结束索引。\n",
    "#   - `text[m.start():m.end()]` 提取匹配的子字符串。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "<re.Match object; span=(5, 20), match='dave@google.com'>\n",
    "'dave@google.com'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex.match(text)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `match()` 仅检查字符串开头是否匹配正则表达式。\n",
    "#   - 因 `text` 开头不是邮箱地址，返回 `None`。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "None\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93be16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regex.sub(\"REDACTED\", text))\n",
    "\n",
    "# - **注释**:\n",
    "#   - `sub(\"REDACTED\", text)` 将所有匹配的邮箱地址替换为 `\"REDACTED\"`。\n",
    "#   - 用于数据脱敏或替换特定模式。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Dave REDACTED\n",
    "Steve REDACTED\n",
    "Rob REDACTED\n",
    "Ryan REDACTED\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3878b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})\"\n",
    "regex = re.compile(pattern, flags=re.IGNORECASE)\n",
    "m = regex.match(\"wesm@bright.net\")\n",
    "m.groups()\n",
    "\n",
    "# - **注释**:\n",
    "#   - 修改正则表达式，使用括号 `()` 定义捕获组，分别匹配用户名、域名和顶级域名。\n",
    "#   - `match()` 检查字符串开头，返回匹配对象。\n",
    "#   - `groups()` 返回捕获组的元组（`wesm`, `bright`, `net`）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "('wesm', 'bright', 'net')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex.findall(text)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `findall()` 返回所有匹配的捕获组元组。\n",
    "#   - 每个元组包含用户名、域名和顶级域名。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "[('dave', 'google', 'com'), ('steve', 'gmail', 'com'), ('rob', 'gmail', 'com'), ('ryan', 'yahoo', 'com')]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdebbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regex.sub(r\"Username: \\1, Domain: \\2, Suffix: \\3\", text))\n",
    "\n",
    "# - **注释**:\n",
    "#   - `sub()` 使用 `\\1`, `\\2`, `\\3` 引用捕获组，格式化替换字符串。\n",
    "#   - 将邮箱地址替换为描述性文本，保留捕获组内容。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Dave Username: dave, Domain: google, Suffix: com\n",
    "Steve Username: steve, Domain: gmail, Suffix: com\n",
    "Rob Username: rob, Domain: gmail, Suffix: com\n",
    "Ryan Username: ryan, Domain: yahoo, Suffix: com\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa9cf0",
   "metadata": {},
   "source": [
    "#### 10.2.3 pandas的矢量化字符串方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series({\"Dave\": \"dave@google.com\", \"Steve\": \"steve@gmail.com\",\n",
    "                  \"Rob\": \"rob@gmail.com\", \"Wes\": np.nan})\n",
    "data\n",
    "\n",
    "# - **注释**:\n",
    "#   - 创建一个Series，包含邮箱地址和一个缺失值（`NaN`）。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Dave     dave@google.com\n",
    "Steve    steve@gmail.com\n",
    "Rob       rob@gmail.com\n",
    "Wes                  NaN\n",
    "dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec002fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.str.contains(\"gmail\")\n",
    "\n",
    "# - **注释**:\n",
    "#   - `str.contains(\"gmail\")` 检查每个字符串是否包含 `\"gmail\"`，返回布尔Series。\n",
    "#   - 缺失值返回 `NaN`，需注意处理。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Dave     False\n",
    "Steve     True\n",
    "Rob       True\n",
    "Wes        NaN\n",
    "dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab31ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.str[:5]\n",
    "\n",
    "# - **注释**:\n",
    "#   - `str[:5]` 提取每个字符串的前5个字符。\n",
    "#   - 矢量化操作，自动跳过 `NaN`。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Dave     dave@\n",
    "Steve    steve\n",
    "Rob      rob@g\n",
    "Wes        NaN\n",
    "dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b76d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})\"\n",
    "data.str.findall(pattern, flags=re.IGNORECASE)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `str.findall(pattern)` 对每个字符串应用正则表达式，提取捕获组。\n",
    "#   - 返回Series，每个元素是匹配的元组列表（或 `NaN`）。\n",
    "#   - `flags=re.IGNORECASE` 忽略大小写。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Dave     [(dave, google, com)]\n",
    "Steve    [(steve, gmail, com)]\n",
    "Rob       [(rob, gmail, com)]\n",
    "Wes                      NaN\n",
    "dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe12851",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = data.str.findall(pattern, flags=re.IGNORECASE).str[0]\n",
    "matches\n",
    "\n",
    "# - **注释**:\n",
    "#   - `str[0]` 提取 `findall()` 结果的第一个匹配元组（每个元素只有一个匹配）。\n",
    "#   - 用于简化后续处理。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Dave     (dave, google, com)\n",
    "Steve    (steve, gmail, com)\n",
    "Rob       (rob, gmail, com)\n",
    "Wes                      NaN\n",
    "dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.str.get(1)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `str.get(1)` 从每个元组中提取第二个元素（域名部分）。\n",
    "#   - 矢量化操作，处理整个Series。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "Dave     google\n",
    "Steve     gmail\n",
    "Rob       gmail\n",
    "Wes         NaN\n",
    "dtype: object\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b10eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.str.extract(pattern, flags=re.IGNORECASE)\n",
    "\n",
    "# - **注释**:\n",
    "#   - `str.extract(pattern)` 提取正则表达式的捕获组，返回DataFrame。\n",
    "#   - 每列对应一个捕获组（用户名、域名、顶级域名）。\n",
    "#   - 缺失值填充为 `NaN`，更适合结构化输出。\n",
    "\n",
    "'''\n",
    "输出结果:\n",
    "          0         1    2\n",
    "Dave   dave   google  com\n",
    "Steve  steve    gmail  com\n",
    "Rob     rob    gmail  com\n",
    "Wes     NaN      NaN  NaN\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea3a8a4",
   "metadata": {},
   "source": [
    "### 10.3 本节重点\n",
    "- **Python内置字符串方法**:\n",
    "  - `split()`, `strip()`, `join()`, `replace()` 等处理基本字符串操作。\n",
    "  - `index()`, `find()`, `count()` 用于查找和计数。\n",
    "  - 适合简单文本处理，但需循环处理Series。\n",
    "- **正则表达式**:\n",
    "  - `re.split()`, `re.findall()`, `re.sub()` 等处理复杂模式匹配。\n",
    "  - `re.compile()` 预编译正则表达式提高效率。\n",
    "  - 捕获组（`()`）和替换引用（`\\1`, `\\2`）支持结构化提取和格式化。\n",
    "  - `flags=re.IGNORECASE` 忽略大小写，增强灵活性。\n",
    "- **pandas矢量化字符串方法**:\n",
    "  - `str.contains()`, `str.findall()`, `str.extract()` 等对Series进行矢量化操作。\n",
    "  - 自动处理 `NaN`，无需显式循环。\n",
    "  - `str.extract()` 返回结构化DataFrame，适合捕获组提取。\n",
    "  - `str.get()` 和 `str[n]` 访问匹配结果的特定部分。\n",
    "- **注意事项**:\n",
    "  - 正则表达式需仔细设计，避免匹配错误或性能问题。\n",
    "  - pandas的 `str` 方法对缺失值友好，但需检查输出类型（Series或DataFrame）。\n",
    "  - 矢量化操作比循环更高效，优先使用。\n",
    "  - 对于大规模数据，预编译正则表达式或优化模式可提升性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d74e9",
   "metadata": {},
   "source": [
    "## 总结 (页码: p216)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cdbc00",
   "metadata": {},
   "source": [
    "## 11. 总结\n",
    "#### 页码: p216\n",
    "\n",
    "### 11.1 章节概述\n",
    "第五章“pandas入门”介绍了pandas库的基础知识和核心功能，涵盖了Series和DataFrame的基本操作、数据索引与选择、算术运算、数据清洗、转换以及字符串处理。以下是本章内容的总结，旨在帮助读者巩固对pandas数据结构和方法的理解，为后续章节（如数据加载、聚合和可视化）打下基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc4c13",
   "metadata": {},
   "source": [
    "### 11.2 主要内容回顾\n",
    "1. **Series和DataFrame简介** (p185-189):\n",
    "   - **Series**：一维带索引的数组，类似带标签的列表。\n",
    "   - **DataFrame**：二维表格结构，类似带行和列标签的电子表格。\n",
    "   - 核心功能包括创建、索引、切片和基本属性访问。\n",
    "\n",
    "2. **基本功能** (p189-194):\n",
    "   - **索引和选择**：使用 `.loc`, `.iloc`, 布尔索引等访问数据。\n",
    "   - **重新索引**：`reindex()` 调整索引顺序或填充缺失值。\n",
    "   - **轴操作**：删除行/列（`drop`）、轴标签管理。\n",
    "\n",
    "3. **算术和数据对齐** (p194-197):\n",
    "   - 自动对齐索引进行算术运算（如 `+`, `-`）。\n",
    "   - 使用 `add()`, `sub()` 等方法控制填充值。\n",
    "   - 处理缺失值（`NaN`）的影响。\n",
    "\n",
    "4. **函数应用和映射** (p197-199):\n",
    "   - `apply()` 和 `applymap()` 对数据应用自定义函数。\n",
    "   - `map()` 对Series进行元素级转换。\n",
    "   - 排序（`sort_index()`, `sort_values()`）和排名（`rank()`）。\n",
    "\n",
    "5. **描述性统计** (p199-201):\n",
    "   - `describe()`, `mean()`, `sum()`, `std()` 等计算统计指标。\n",
    "   - 相关性（`corr()`）和协方差（`cov()`）。\n",
    "   - 唯一值（`unique()`）、计数（`value_counts()`）等。\n",
    "\n",
    "6. **处理缺失值** (p201-204):\n",
    "   - 检测（`isna()`, `notna()`）、删除（`dropna()`）、填充（`fillna()`）。\n",
    "   - 灵活的参数控制（如 `how`, `axis`, `method`）。\n",
    "\n",
    "7. **数据转换** (p204-211):\n",
    "   - 移除重复（`duplicated()`, `drop_duplicates()`）。\n",
    "   - 映射（`map()`）、替换（`replace()`）、重命名（`rename()`）。\n",
    "   - 离散化（`cut()`, `qcut()`）、异常值处理、随机采样（`sample()`）。\n",
    "\n",
    "8. **计算指标/虚拟变量** (p211-213):\n",
    "   - `get_dummies()` 创建虚拟变量，处理分类数据。\n",
    "   - 多类别处理（如电影类型拆分）和分箱结合虚拟变量。\n",
    "\n",
    "9. **字符串操作** (p213-216):\n",
    "   - Python内置方法（`split()`, `strip()`, `join()` 等）。\n",
    "   - 正则表达式（`re.split()`, `re.findall()`, `re.sub()`）。\n",
    "   - pandas矢量化方法（`str.contains()`, `str.extract()` 等）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3add10",
   "metadata": {},
   "source": [
    "### 11.3 本节重点\n",
    "- **核心理念**:\n",
    "  - pandas通过Series和DataFrame提供灵活、高效的数据操作。\n",
    "  - 索引对齐和矢量化运算是pandas的独特优势。\n",
    "  - 数据清洗和预处理（如缺失值、重复值、字符串处理）是分析的关键步骤。\n",
    "\n",
    "- **实用技巧**:\n",
    "  - 优先使用矢量化操作（如 `str` 方法、算术方法）而非循环。\n",
    "  - 合理选择索引方法（`.loc`, `.iloc`）避免歧义。\n",
    "  - 结合正则表达式和 `get_dummies()` 增强特征工程能力。\n",
    "\n",
    "- **注意事项**:\n",
    "  - 注意操作是否返回新对象（如 `dropna()`, `replace()`），需赋值或使用 `inplace=True`。\n",
    "  - 处理大规模数据时，优化正则表达式或使用稀疏矩阵。\n",
    "  - 缺失值和异常值的处理需根据业务场景选择策略。\n",
    "\n",
    "- **后续学习**:\n",
    "  - 第六章将介绍数据加载和存储（如CSV、JSON、Excel）。\n",
    "  - 第七章将深入数据聚合和分组操作。\n",
    "  - 掌握第五章的基础操作是后续分析和建模的前提。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
