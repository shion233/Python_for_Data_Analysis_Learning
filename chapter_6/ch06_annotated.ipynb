{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e67d6621",
   "metadata": {},
   "source": [
    "# 利用Python进行数据分析（第二版）——第六章数据加载、存储与文件格式 (p225)\n",
    "本章介绍了pandas中用于数据加载、存储和文件格式处理的核心工具，帮助用户高效读写多种数据源。主要内容包括：\n",
    "- **CSV和文本文件**：通过`read_csv`和`read_table`读取常见文本数据。\n",
    "- **JSON和HTML**：处理结构化JSON数据和网页中的HTML表格。\n",
    "- **Excel文件**：使用`read_excel`和`to_excel`操作Excel表格。\n",
    "- **数据库交互**：实现与SQL数据库的连接和数据读写。\n",
    "**重点**：掌握`read_csv`的灵活参数配置，以适应不同格式的文本文件（如分隔符、缺失值处理等）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b81cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入核心库，用于数据分析和可视化\n",
    "# np.random.seed：设置随机种子，确保结果可复现\n",
    "# plt.rc：配置matplotlib图形默认尺寸为10x6\n",
    "# pd.options：优化pandas输出显示，如列宽和列数限制\n",
    "# np.set_printoptions：设置numpy数组打印精度为4位小数并禁用科学计数法\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(12345)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"figure\", figsize=(10, 6))\n",
    "pd.options.display.max_colwidth = 75\n",
    "pd.options.display.max_columns = 20\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50418b8a",
   "metadata": {},
   "source": [
    "## 6.2 读写文本格式的数据 (p225)\n",
    "本节详细讲解了使用pandas的`read_csv`和`read_table`等函数读取和处理文本格式数据（如CSV、TXT等）。通过灵活的参数配置，可以处理不同分隔符、缺失值、索引列等场景。\n",
    "**核心内容**：\n",
    "- **读取CSV文件**：使用`pd.read_csv`加载标准CSV文件，支持自定义列名、索引、分隔符等。\n",
    "- **处理缺失值**：通过`na_values`参数指定缺失值标记。\n",
    "- **跳过无关行**：使用`skiprows`跳过文件中的注释或无关行。\n",
    "- **灵活分隔符**：通过`sep`参数处理非逗号分隔的文本文件（如空格分隔）。\n",
    "**重点**：熟练掌握`read_csv`的常用参数（如`header`、`names`、`index_col`、`na_values`、`skiprows`、`sep`），以适应复杂数据格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df773e2e",
   "metadata": {},
   "source": [
    "### 6.2.1 读取标准CSV文件\n",
    "以下示例展示如何读取一个标准CSV文件`ex1.csv`，并查看其内容。文件包含列名和数据行，格式为逗号分隔。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca152e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用!type命令查看ex1.csv文件内容（Windows系统）\n",
    "# 文件格式：逗号分隔，包含列名（a,b,c,d,message）和三行数据\n",
    "\n",
    "!type examples\\ex1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用pd.read_csv读取ex1.csv\n",
    "# 默认以第一行为列名，生成DataFrame\n",
    "\n",
    "df = pd.read_csv(\"examples/ex1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ad88c",
   "metadata": {},
   "source": [
    "### 6.2.2 处理无列名的CSV文件\n",
    "对于没有列名的CSV文件（如`ex2.csv`），可以通过`header=None`或`names`参数手动指定列名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05622c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看ex2.csv文件内容，无列名，仅包含数据行\n",
    "\n",
    "!type examples\\ex2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc6687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# header=None：不将第一行作为列名，自动生成数字索引\n",
    "# names：手动指定列名列表\n",
    "\n",
    "pd.read_csv(\"examples/ex2.csv\", header=None)\n",
    "pd.read_csv(\"examples/ex2.csv\", names=[\"a\", \"b\", \"c\", \"d\", \"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6425d2",
   "metadata": {},
   "source": [
    "### 6.2.3 设置索引列\n",
    "通过`index_col`参数，可以指定某列作为DataFrame的索引。例如，将`message`列设为索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8475182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names：定义列名\n",
    "# index_col：指定'message'列作为索引\n",
    "\n",
    "names = [\"a\", \"b\", \"c\", \"d\", \"message\"]\n",
    "pd.read_csv(\"examples/ex2.csv\", names=names, index_col=\"message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5d683f",
   "metadata": {},
   "source": [
    "### 6.2.4 多层索引\n",
    "对于具有层次结构的CSV文件（如`csv_mindex.csv`），可以通过`index_col`指定多个列作为多层索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54edbe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看csv_mindex.csv文件内容，包含两列索引（key1, key2）和两列数据（value1, value2）\n",
    "# index_col=[\"key1\", \"key2\"]：指定多层索引\n",
    "\n",
    "!type examples\\csv_mindex.csv\n",
    "parsed = pd.read_csv(\"examples/csv_mindex.csv\", index_col=[\"key1\", \"key2\"])\n",
    "parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fdb0ee",
   "metadata": {},
   "source": [
    "### 6.2.5 处理非逗号分隔的文本文件\n",
    "对于非逗号分隔的文本文件（如空格分隔的`ex3.txt`），通过`sep`参数指定分隔符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd97663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看ex3.txt文件内容，使用多个空格分隔\n",
    "\n",
    "!type examples\\ex3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sep=r\"\\s+\"：使用正则表达式匹配一个或多个空格作为分隔符\n",
    "\n",
    "result = pd.read_csv(\"examples/ex3.txt\", sep=r\"\\s+\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcce98a",
   "metadata": {},
   "source": [
    "### 6.2.6 跳过无关行\n",
    "对于包含注释或无关行的CSV文件（如`ex4.csv`），使用`skiprows`参数跳过指定行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看ex4.csv文件内容，包含注释行（#开头）\n",
    "# skiprows=[0, 2, 3]：跳过第0、2、3行\n",
    "\n",
    "!type examples\\ex4.csv\n",
    "pd.read_csv(\"examples/ex4.csv\", skiprows=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f83fa",
   "metadata": {},
   "source": [
    "### 6.2.7 处理缺失值\n",
    "pandas自动识别常见缺失值（如空值、NA），并支持通过`na_values`自定义缺失值标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看ex5.csv文件内容，包含缺失值（如NA、空值）\n",
    "# 读取ex5.csv，自动识别缺失值\n",
    "\n",
    "!type examples\\ex5.csv\n",
    "result = pd.read_csv(\"examples/ex5.csv\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a81f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.isna：检查DataFrame中的缺失值，返回布尔值矩阵\n",
    "\n",
    "pd.isna(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88872d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# na_values=[\"NULL\"]：将'NULL'标记为缺失值\n",
    "\n",
    "result = pd.read_csv(\"examples/ex5.csv\", na_values=[\"NULL\"])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d57ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep_default_na=False：禁用默认缺失值识别\n",
    "# na_values=[\"NA\"]：仅将'NA'标记为缺失值\n",
    "# result2：展示禁用默认缺失值后的效果\n",
    "# result3：展示自定义缺失值后的效果\n",
    "\n",
    "result2 = pd.read_csv(\"examples/ex5.csv\", keep_default_na=False)\n",
    "result2\n",
    "result2.isna()\n",
    "result3 = pd.read_csv(\"examples/ex5.csv\", keep_default_na=False, na_values=[\"NA\"])\n",
    "result3\n",
    "result3.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca58761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentinels：为不同列指定不同的缺失值标记\n",
    "# keep_default_na=False：避免默认缺失值干扰\n",
    "\n",
    "sentinels = {\"message\": [\"foo\", \"NA\"], \"something\": [\"two\"]}\n",
    "pd.read_csv(\"examples/ex5.csv\", na_values=sentinels, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a9065",
   "metadata": {},
   "source": [
    "**小结**：\n",
    "本节通过多个示例展示了`pd.read_csv`的强大功能，包括处理标准CSV、无列名文件、多层索引、非逗号分隔文件、注释行和缺失值等场景。关键在于灵活使用参数（如`header`、`names`、`index_col`、`sep`、`skiprows`、`na_values`），以适应不同数据格式。掌握这些技巧可以高效处理各种文本数据，为后续分析奠定基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef04cb",
   "metadata": {},
   "source": [
    "## 6.3 逐块读取文本文件 (p233)\n",
    "本节介绍了如何使用pandas处理大型文本文件，通过逐块读取（chunking）技术减少内存占用，适合处理无法一次性加载到内存的大数据集。\n",
    "**核心内容**：\n",
    "- **限制行数读取**：使用`nrows`参数读取文件的前几行。\n",
    "- **逐块读取**：通过`chunksize`参数分块读取文件，生成迭代器。\n",
    "- **显示优化**：调整pandas显示选项（如`max_rows`）以简化输出。\n",
    "**重点**：掌握`chunksize`参数的使用，结合迭代器逐块处理大型数据集，优化内存使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d7a6a",
   "metadata": {},
   "source": [
    "### 6.3.1 设置显示行数\n",
    "通过设置`pd.options.display.max_rows`，限制DataFrame输出时的最大行数，方便查看大型数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e93f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置pandas显示最大行数为10，防止输出过多行\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aeef5b",
   "metadata": {},
   "source": [
    "### 6.3.2 读取大型CSV文件\n",
    "以下示例展示了如何读取一个大型CSV文件`ex6.csv`，并查看其内容。文件包含多列（`one`, `two`, `three`, `four`, `key`）和10000行数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d06aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取ex6.csv，生成包含10000行的DataFrame\n",
    "# 输出显示受max_rows限制，仅展示部分行\n",
    "\n",
    "result = pd.read_csv(\"examples/ex6.csv\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ca7de5",
   "metadata": {},
   "source": [
    "### 6.3.3 限制读取行数\n",
    "通过`nrows`参数，可以仅读取文件的前几行，适合快速预览数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ef57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nrows=5：仅读取ex6.csv的前5行\n",
    "\n",
    "pd.read_csv(\"examples/ex6.csv\", nrows=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64101ebb",
   "metadata": {},
   "source": [
    "**小结**：\n",
    "本节介绍了处理大型文本文件的逐块读取技术，通过`nrows`参数快速预览数据，以及`pd.options.display.max_rows`优化输出显示。虽然文档中未直接展示`chunksize`的使用，但这是逐块读取的核心参数（可结合`pd.read_csv`的迭代器功能）。这些方法有效降低了内存占用，适合处理大数据集，为后续数据分析提供了高效支持。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03399c34",
   "metadata": {},
   "source": [
    "## 6.4 读取HTML和XML数据\n",
    "本节介绍了如何使用pandas从HTML网页和XML文件中提取结构化数据，适用于网络数据抓取和特定格式的数据处理。\n",
    "**核心内容**：\n",
    "- **读取HTML表格**：使用`pd.read_html`从网页中提取表格数据。\n",
    "- **处理XML数据**：通过`lxml`库解析XML文件，或使用`pd.read_xml`直接读取。\n",
    "- **数据后处理**：结合pandas功能对提取的数据进行清洗和分析（如时间戳转换）。\n",
    "**重点**：掌握`pd.read_html`提取HTML表格和`pd.read_xml`处理XML数据的用法，理解如何结合其他库（如`lxml objectify`）解析复杂XML结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c09700",
   "metadata": {},
   "source": [
    "### 6.4.1 读取HTML表格\n",
    "`pd.read_html`可以从HTML文件中提取所有`<table>`标签中的表格数据，返回一个DataFrame列表。以下示例从`fdic_failed_bank_list.html`中提取银行倒闭数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取HTML文件中的表格，返回DataFrame列表\n",
    "# tables[0]：提取第一个表格，包含银行倒闭信息\n",
    "# failures.head()：显示前5行数据\n",
    "\n",
    "tables = pd.read_html(\"examples/fdic_failed_bank_list.html\")\n",
    "len(tables)\n",
    "failures = tables[0]\n",
    "failures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7925a",
   "metadata": {},
   "source": [
    "### 6.4.2 分析HTML表格数据\n",
    "提取的表格数据可以进一步分析。例如，将`Closing Date`列转换为时间戳，并统计每年银行倒闭数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dced7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_datetime：将Closing Date列转换为时间戳\n",
    "# dt.year.value_counts()：统计每年银行倒闭次数\n",
    "\n",
    "close_timestamps = pd.to_datetime(failures[\"Closing Date\"])\n",
    "close_timestamps.dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7474b3d3",
   "metadata": {},
   "source": [
    "### 6.4.3 解析XML数据（使用lxml）\n",
    "对于XML格式数据，可以使用`lxml.objectify`解析文件，并手动构建DataFrame。以下示例处理地铁北铁路（Metro-North Railroad）的性能数据`Performance_MNR.xml`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcaa539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入lxml.objectify用于解析XML文件\n",
    "# 打开Performance_MNR.xml并获取根节点\n",
    "\n",
    "from lxml import objectify\n",
    "\n",
    "path = \"../datasets/mta_perf/Performance_MNR.xml\"\n",
    "with open(path) as f:\n",
    "    parsed = objectify.parse(f)\n",
    "root = parsed.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义要跳过的字段（无关数据）\n",
    "# 遍历XML的INDICATOR节点，提取所需字段\n",
    "# 构建字典列表并转换为DataFrame\n",
    "\n",
    "data = []\n",
    "\n",
    "skip_fields = [\"PARENT_SEQ\", \"INDICATOR_SEQ\", \"DESIRED_CHANGE\", \"DECIMAL_PLACES\"]\n",
    "\n",
    "for elt in root.INDICATOR:\n",
    "    el_data = {}\n",
    "    for child in elt.getchildren():\n",
    "        if child.tag in skip_fields:\n",
    "            continue\n",
    "        el_data[child.tag] = child.pyval\n",
    "    data.append(el_data)\n",
    "\n",
    "perf = pd.DataFrame(data)\n",
    "perf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ece54",
   "metadata": {},
   "source": [
    "### 6.4.4 使用pd.read_xml直接读取XML\n",
    "pandas提供`read_xml`函数，可直接将XML文件转换为DataFrame，简化处理流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_xml：直接读取XML文件并生成DataFrame\n",
    "# head()：显示前5行数据\n",
    "\n",
    "perf2 = pd.read_xml(path)\n",
    "perf2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720990c8",
   "metadata": {},
   "source": [
    "**小结**：\n",
    "本节展示了从HTML和XML格式中提取结构化数据的技巧。`pd.read_html`能高效提取网页中的表格数据，结合pandas的时间序列功能（如`pd.to_datetime`）可进行深入分析。XML数据处理则提供了两种方式：使用`lxml.objectify`手动解析复杂结构，或通过`pd.read_xml`直接读取。这些方法为处理网络数据和特定格式文件提供了灵活支持，适用于数据抓取和清洗场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d77e3a0",
   "metadata": {},
   "source": [
    "## 6.5 二进制数据格式 (p247)\n",
    "本节介绍了pandas处理二进制数据格式的方法，包括Pickle、Parquet和HDF5格式。这些格式相比文本文件更高效，适合存储大型数据集或需要快速读写的场景。\n",
    "**核心内容**：\n",
    "- **Pickle格式**：使用`to_pickle`和`read_pickle`序列化和反序列化pandas对象。\n",
    "- **Parquet格式**：通过`read_parquet`读取高效的列式存储格式。\n",
    "- **HDF5格式**：使用`HDFStore`或`to_hdf`/`read_hdf`处理高性能分层数据格式，支持部分读取和查询。\n",
    "**重点**：理解不同二进制格式的适用场景，掌握`HDFStore`的高级用法（如查询和表格式存储）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3609ac",
   "metadata": {},
   "source": [
    "### 6.5.1 Pickle格式\n",
    "Pickle是Python的内置序列化格式，pandas通过`to_pickle`和`read_pickle`支持快速保存和读取DataFrame。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86c9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取ex1.csv生成DataFrame\n",
    "# to_pickle：将DataFrame序列化保存为Pickle文件\n",
    "\n",
    "frame = pd.read_csv(\"../examples/ex1.csv\")\n",
    "frame.to_pickle(\"../examples/frame_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_pickle：从Pickle文件读取DataFrame\n",
    "\n",
    "pd.read_pickle(\"../examples/frame_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除生成的Pickle文件，清理临时文件\n",
    "\n",
    "!del ..\\examples\\frame_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b100044",
   "metadata": {},
   "source": [
    "### 6.5.2 Parquet格式\n",
    "Parquet是一种高效的列式存储格式，适合大数据处理。pandas通过`read_parquet`支持读取Parquet文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cf5f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取Parquet格式的fec数据集\n",
    "\n",
    "fec = pd.read_parquet('../datasets/fec/fec.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c2d05e",
   "metadata": {},
   "source": [
    "### 6.5.3 HDF5格式\n",
    "HDF5是一种高性能的分层数据格式，pandas通过`HDFStore`或`to_hdf`/`read_hdf`支持读写，支持部分数据查询和表格式存储。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建包含随机数据的DataFrame\n",
    "# HDFStore：打开HDF5文件，存储DataFrame和单列\n",
    "# store['obj1']：保存整个DataFrame\n",
    "# store['obj1_col']：保存DataFrame的'a'列\n",
    "\n",
    "frame = pd.DataFrame({\"a\": np.random.standard_normal(100)})\n",
    "store = pd.HDFStore(\"../examples/mydata.h5\")\n",
    "store[\"obj1\"] = frame\n",
    "store[\"obj1_col\"] = frame[\"a\"]\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从HDFStore读取obj1对应的DataFrame\n",
    "\n",
    "store[\"obj1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put：以表格式存储DataFrame，支持查询\n",
    "# select：通过where条件查询索引在10到15之间的数据\n",
    "# close：关闭HDFStore连接\n",
    "\n",
    "store.put(\"obj2\", frame, format=\"table\")\n",
    "store.select(\"obj2\", where=[\"index >= 10 and index <= 15\"])\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6286f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_hdf：直接将DataFrame保存为HDF5文件（表格式）\n",
    "# read_hdf：读取HDF5文件，where条件限制索引小于5\n",
    "\n",
    "frame.to_hdf(path_or_buf=\"examples/mydata.h5\", key=\"obj3\", format=\"table\")\n",
    "pd.read_hdf(path_or_buf=\"examples/mydata.h5\", key=\"obj3\", where=[\"index < 5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc94305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除生成的HDF5文件，清理临时文件\n",
    "\n",
    "import os\n",
    "os.remove(\"examples/mydata.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28efbfd",
   "metadata": {},
   "source": [
    "**小结**：\n",
    "本节展示了pandas处理二进制数据格式的强大功能。Pickle格式通过`to_pickle`和`read_pickle`实现快速序列化，适合小型数据集。Parquet格式通过`read_parquet`支持高效列式存储，适用于大数据场景。HDF5格式通过`HDFStore`和`to_hdf`/`read_hdf`提供高性能读写和查询功能，特别适合需要部分数据加载的大型数据集。这些格式显著提升了数据存储和读取效率，为复杂数据分析提供了灵活支持。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1d844",
   "metadata": {},
   "source": [
    "## 6.6 读取Microsoft Excel文件 (p251)\n",
    "本节介绍了使用pandas读取和写入Microsoft Excel文件的方法，通过`pd.ExcelFile`和`pd.read_excel`处理Excel表格数据，支持多Sheet操作和灵活的索引设置。\n",
    "**核心内容**：\n",
    "- **读取Excel文件**：使用`pd.ExcelFile`加载Excel文件，或直接用`pd.read_excel`读取指定Sheet。\n",
    "- **写入Excel文件**：通过`to_excel`和`ExcelWriter`将DataFrame保存为Excel文件。\n",
    "- **Sheet和索引管理**：支持指定Sheet名称、索引列，以及处理多Sheet文件。\n",
    "**重点**：掌握`pd.read_excel`和`to_excel`的基本用法，理解如何通过`ExcelWriter`实现多Sheet写入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966e10d",
   "metadata": {},
   "source": [
    "### 6.6.1 使用pd.ExcelFile读取Excel文件\n",
    "`pd.ExcelFile`用于加载Excel文件，支持访问多个Sheet。以下示例读取`ex1.xlsx`中的Sheet数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d4e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建ExcelFile对象，加载ex1.xlsx文件\n",
    "\n",
    "xlsx = pd.ExcelFile(\"../examples/ex1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52391d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet_names：查看Excel文件中的Sheet名称列表\n",
    "\n",
    "xlsx.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0918f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse：读取指定Sheet（Sheet1）的数据，生成DataFrame\n",
    "\n",
    "xlsx.parse(sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8613ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse：读取Sheet1，并将第0列设为索引\n",
    "\n",
    "xlsx.parse(sheet_name=\"Sheet1\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b524042",
   "metadata": {},
   "source": [
    "### 6.6.2 使用pd.read_excel直接读取\n",
    "`pd.read_excel`可以直接读取Excel文件的指定Sheet，简化操作流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ecdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接读取ex1.xlsx的Sheet1，生成DataFrame\n",
    "\n",
    "frame = pd.read_excel(\"../examples/ex1.xlsx\", sheet_name=\"Sheet1\")\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739c34b3",
   "metadata": {},
   "source": [
    "### 6.6.3 写入Excel文件\n",
    "通过`to_excel`和`ExcelWriter`，可以将DataFrame保存为Excel文件，支持多Sheet写入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd22c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建ExcelWriter对象，指定输出文件ex2.xlsx\n",
    "# to_excel：将frame写入Sheet1\n",
    "# close：保存并关闭ExcelWriter\n",
    "\n",
    "writer = pd.ExcelWriter(\"../examples/ex2.xlsx\")\n",
    "frame.to_excel(excel_writer=writer, sheet_name=\"Sheet1\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_excel：直接将frame保存为ex2.xlsx，默认Sheet名称为Sheet1\n",
    "\n",
    "frame.to_excel(\"../examples/ex2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79691607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除生成的ex2.xlsx文件，清理临时文件\n",
    "\n",
    "!del ..\\examples\\ex2.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094cf1c1",
   "metadata": {},
   "source": [
    "**小结**：\n",
    "本节展示了pandas处理Excel文件的核心功能。`pd.ExcelFile`通过加载整个Excel文件支持多Sheet访问，而`pd.read_excel`提供更便捷的单Sheet读取方式。写入方面，`to_excel`可直接生成Excel文件，结合`ExcelWriter`支持多Sheet写入。这些工具简化了Excel数据的读写流程，特别适合处理财务、报表等常见场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ddf18a",
   "metadata": {},
   "source": [
    "## 6.7 Web APIs交互 (p252)\n",
    "本节介绍了如何通过Python的`requests`库与Web API交互，获取JSON格式的数据，并使用pandas进行处理。Web API是获取实时网络数据的常见方式。\n",
    "**核心内容**：\n",
    "- **使用requests库**：发送HTTP请求获取API返回的JSON数据。\n",
    "- **JSON数据处理**：将API返回的JSON转换为pandas DataFrame。\n",
    "- **示例场景**：从GitHub API获取pandas项目的issues数据。\n",
    "**重点**：掌握`requests.get`获取API数据和`json()`方法解析JSON的流程，理解如何将嵌套JSON结构转换为DataFrame。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e82178c",
   "metadata": {},
   "source": [
    "### 6.7.1 从GitHub API获取数据\n",
    "以下示例通过GitHub API获取pandas项目的issues数据，并将其转换为DataFrame。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb1327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入requests库，用于发送HTTP请求\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641406a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义GitHub API的URL，获取pandas项目的issues\n",
    "# requests.get：发送GET请求获取API响应\n",
    "# resp.json()：解析响应为JSON格式\n",
    "\n",
    "url = \"https://api.github.com/repos/pandas-dev/pandas/issues\"\n",
    "resp = requests.get(url)\n",
    "resp.raise_for_status()\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ae32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取JSON数据，resp.json()返回列表，每个元素为一个issue\n",
    "# 查看第一个issue的title字段\n",
    "\n",
    "data = resp.json()\n",
    "data[0][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edfca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将JSON数据转换为DataFrame，自动提取所有字段\n",
    "# head()：显示前5行数据\n",
    "\n",
    "issues = pd.DataFrame(data)\n",
    "issues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e881a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择感兴趣的列（如number, title, state, created_at等）\n",
    "# 生成新的DataFrame，仅包含指定列\n",
    "\n",
    "issues = pd.DataFrame(data, columns=[\"number\", \"title\", \"labels\", \"state\", \"created_at\", \"updated_at\", \"user\"])\n",
    "issues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b1263",
   "metadata": {},
   "source": [
    "**小结**：\n",
    "本节展示了通过`requests`库与Web API交互的核心流程。以GitHub API为例，演示了如何发送GET请求、解析JSON响应，并将嵌套JSON数据转换为pandas DataFrame。关键在于理解API返回数据的结构，使用`pd.DataFrame`提取所需字段并进行后续分析。这种方法适用于从各种Web API获取实时数据，如社交媒体、财务数据等场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b983ad3c",
   "metadata": {},
   "source": [
    "## 6.8 数据库交互 (p254)\n",
    "本节介绍了如何使用pandas与关系型数据库（如SQLite、MySQL、PostgreSQL）交互，通过`sqlite3`和`sqlalchemy`实现数据读写。数据库是存储和查询结构化数据的重要工具，pandas提供了高效的接口。\n",
    "**核心内容**：\n",
    "- **SQLite数据库**：使用`sqlite3`创建内存数据库并执行SQL操作。\n",
    "- **pandas与SQL交互**：通过`to_sql`将DataFrame写入数据库，`read_sql`从数据库读取数据。\n",
    "- **SQLAlchemy支持**：支持更广泛的数据库引擎（如MySQL、PostgreSQL）。\n",
    "**重点**：掌握`to_sql`和`read_sql`的用法，理解如何结合`sqlite3`或`sqlalchemy`实现数据库操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3aea27",
   "metadata": {},
   "source": [
    "### 6.8.1 使用sqlite3操作SQLite数据库\n",
    "以下示例展示如何使用`sqlite3`创建内存数据库，插入数据，并通过pandas进行读写。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36482b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入sqlite3库，用于操作SQLite数据库\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff637f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建内存数据库（:memory:）\n",
    "# 定义SQL语句，创建mytable表（包含a, b, c, d列）\n",
    "# 执行SQL语句创建表\n",
    "\n",
    "query = \"\"\"\n",
    "CREATE TABLE mytable\n",
    "(a VARCHAR(20), b VARCHAR(20),\n",
    "c REAL, d INTEGER);\n",
    "\"\"\"\n",
    "\n",
    "con = sqlite3.connect(\":memory:\")\n",
    "con.execute(query)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e885f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义要插入的数据（元组列表）\n",
    "# 执行插入操作，将数据写入mytable表\n",
    "# 提交事务\n",
    "\n",
    "data = [\n",
    "    (\"Atlanta\", \"Georgia\", 1.25, 6),\n",
    "    (\"Tallahassee\", \"Florida\", 2.6, 3),\n",
    "    (\"Sacramento\", \"California\", 1.7, 5),\n",
    "]\n",
    "stmt = \"INSERT INTO mytable VALUES(?, ?, ?, ?)\"\n",
    "con.executemany(stmt, data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae7e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行SELECT查询，获取mytable表的所有数据\n",
    "# fetchall()：获取查询结果（元组列表）\n",
    "\n",
    "cursor = con.execute(\"SELECT * FROM mytable\")\n",
    "rows = cursor.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14604635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# description：获取表列名\n",
    "# pd.DataFrame：将查询结果转换为DataFrame，指定列名\n",
    "\n",
    "cursor.description\n",
    "pd.DataFrame(rows, columns=[x[0] for x in cursor.description])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1109a10",
   "metadata": {},
   "source": [
    "### 6.8.2 使用pandas直接读写数据库\n",
    "`read_sql`和`to_sql`提供了更便捷的数据库交互方式，直接将SQL查询结果转换为DataFrame，或将DataFrame写入数据库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e8548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_sql：执行SELECT查询，直接生成DataFrame\n",
    "# con：指定数据库连接\n",
    "\n",
    "pd.read_sql(\"SELECT * FROM mytable\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c615cb",
   "metadata": {},
   "source": [
    "**小结**：\n",
    "本节展示了pandas与关系型数据库交互的流程。以SQLite为例，通过`sqlite3`创建内存数据库并执行SQL操作，结合`pd.read_sql`直接将查询结果转换为DataFrame。`to_sql`（虽未在示例中展示）可将DataFrame写入数据库。这些工具简化了数据库操作，适合需要从数据库提取数据或存储分析结果的场景。`sqlalchemy`支持更复杂的数据库引擎，扩展了适用范围。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd83fc1",
   "metadata": {},
   "source": [
    "# 第六章总结：数据加载、存储与文件格式\n",
    "第六章全面介绍了pandas处理多种数据源和格式的工具与技术，涵盖文本文件、二进制格式、Excel文件、Web API以及数据库交互。以下是各小节的核心内容、关键技术和应用场景总结：\n",
    "## 1. 数据加载、存储与文件格式 (p225)\n",
    "- **核心内容**：介绍了pandas数据加载与存储的基础工具，包括`read_csv`、`read_excel`、JSON/HTML处理和数据库交互。\n",
    "- **关键技术**：初始化分析环境（设置随机种子、显示选项），掌握`read_csv`的灵活参数配置。\n",
    "- **应用场景**：为数据分析奠定基础，适用于多种数据格式的预处理。\n",
    "## 2. 读写文本格式的数据 (p225)\n",
    "- **核心内容**：详细讲解`read_csv`和`read_table`，支持处理分隔符、缺失值、索引列等复杂场景。\n",
    "- **关键技术**：`header`、`names`、`index_col`、`sep`、`skiprows`、`na_values`等参数的灵活使用。\n",
    "- **应用场景**：处理CSV、TXT等文本文件，清洗非标准数据。\n",
    "## 3. 逐块读取文本文件 (p233)\n",
    "- **核心内容**：通过`nrows`和`chunksize`处理大型文本文件，优化内存使用。\n",
    "- **关键技术**：`nrows`限制行数，`pd.options.display.max_rows`优化输出。\n",
    "- **应用场景**：处理超大CSV文件，适合内存受限环境。\n",
    "## 4. 读取HTML和XML数据\n",
    "- **核心内容**：使用`pd.read_html`提取HTML表格，`lxml`或`pd.read_xml`解析XML数据。\n",
    "- **关键技术**：`pd.read_html`生成DataFrame列表，`lxml.objectify`处理复杂XML结构。\n",
    "- **应用场景**：网络数据抓取（如网页表格）、XML格式数据处理。\n",
    "## 5. 二进制数据格式 (p247)\n",
    "- **核心内容**：介绍Pickle、Parquet、HDF5格式，支持高效存储和快速读写。\n",
    "- **关键技术**：`to_pickle`/`read_pickle`、`read_parquet`、`HDFStore`的表格式存储与查询。\n",
    "- **应用场景**：存储大型数据集，优化大数据分析性能。\n",
    "## 6. 读取Microsoft Excel文件 (p251)\n",
    "- **核心内容**：通过`pd.ExcelFile`和`pd.read_excel`读取Excel，`to_excel`写入数据。\n",
    "- **关键技术**：`ExcelWriter`支持多Sheet写入，`index_col`管理索引。\n",
    "- **应用场景**：处理财务报表、共享Excel数据。\n",
    "## 7. Web APIs交互 (p252)\n",
    "- **核心内容**：使用`requests`库获取JSON数据，转换为DataFrame。\n",
    "- **关键技术**：`requests.get`发送HTTP请求，`json()`解析API响应。\n",
    "- **应用场景**：实时获取网络数据（如GitHub issues、财务API）。\n",
    "## 8. 数据库交互 (p254)\n",
    "- **核心内容**：通过`sqlite3`或`sqlalchemy`与数据库交互，`read_sql`和`to_sql`简化操作。\n",
    "- **关键技术**：`sqlite3`创建内存数据库，`read_sql`直接生成DataFrame。\n",
    "- **应用场景**：从SQL数据库提取数据，存储分析结果。\n",
    "## 总体评价\n",
    "第六章展示了pandas在数据加载与存储方面的强大功能，从简单的CSV文件到复杂的数据库和Web API，覆盖了数据分析的常见场景。核心在于灵活的参数配置（如`read_csv`）和高效的格式支持（如HDF5）。学习重点是掌握各方法的适用场景和参数用法，结合实际需求选择合适的工具。\n",
    "**建议**：通过实践不同数据源的读写操作，熟练掌握参数配置和异常处理，提升数据预处理效率。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
